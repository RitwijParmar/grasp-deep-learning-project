{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f574216-c07a-4c31-83e2-22790e5d2497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting Post-Pretraining Qualitative Evaluation \n",
      "Using encoders directly from trained model in memory.\n",
      "\n",
      " Cosine Similarity Matrix (Graph vs. SMILES) \n",
      "Rows: Graph Embeddings of [SMILES]\n",
      "Cols: SMILES Embeddings of [SMILES]\n",
      "          CCO       c1ccccc1  O=C(Cl)c  CC(=O)Oc  C         \n",
      "------------------------------------------------------------\n",
      "CCO       -0.0233   -0.0285   -0.0415   -0.0385   -0.0555   \n",
      "c1ccccc1  -0.0123   -0.0068   -0.0257   -0.0207   -0.0375   \n",
      "O=C(Cl)c  -0.0238   -0.0172   -0.0354   -0.0293   -0.0501   \n",
      "CC(=O)Oc  -0.0284   -0.0225   -0.0409   -0.0353   -0.0532   \n",
      "C         -0.0215   -0.0135   -0.0130   -0.0155   -0.0526   \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Starting Post-Pretraining Qualitative Evaluation \")\n",
    "\n",
    "try:\n",
    "    if 'model' not in locals() or not hasattr(model, 'gin_encoder') or not hasattr(model, 'transformer_encoder'):\n",
    "        print(\"Loading encoders from disk...\")\n",
    "        loaded_gin_encoder = tf.saved_model.load('gin_encoder_pretrained')\n",
    "        loaded_transformer_encoder = tf.saved_model.load('transformer_encoder_pretrained')\n",
    "    else:\n",
    "        print(\"Using encoders directly from trained model in memory.\")\n",
    "        loaded_gin_encoder = model.gin_encoder\n",
    "        loaded_transformer_encoder = model.transformer_encoder\n",
    "# Exiting if encoders cant be loaded\n",
    "except Exception as e:\n",
    "    print(f\"Error loading encoders: {e}. Make sure they were saved correctly and paths are valid.\")\n",
    "    print(\"Skipping qualitative evaluation.\")\n",
    "    exit() \n",
    "\n",
    "def get_single_molecule_embeddings(smiles_string, gin_encoder, transformer_encoder):\n",
    "# to get embeddings for a single SMILES string\n",
    "    \n",
    "    token_ids = tokenize_smiles(smiles_string, char_to_idx, MAX_SMILES_LEN)\n",
    "    smiles_mask = create_smiles_mask(token_ids, char_to_idx['<pad>'])\n",
    "\n",
    "    node_features, edge_indices, num_nodes, num_edges = smiles_to_tf_graph(smiles_string)\n",
    "\n",
    "    if node_features is None or num_nodes == 0:\n",
    "        print(f\"Warning: Could not featurize SMILES '{smiles_string}'. Skipping.\")\n",
    "        return None, None\n",
    "    \n",
    "    # padding the node_features to MAX_NODES for consistent shape\n",
    "    padded_node_features = tf.pad(node_features, [[0, MAX_NODES - num_nodes], [0, 0]])\n",
    "    \n",
    "    node_features_for_gin = tf.reshape(padded_node_features, (1 * MAX_NODES, NUM_ATOM_FEATURES)) \n",
    "\n",
    "    edge_indices_for_gin = tf.cast(edge_indices, dtype=tf.int32) \n",
    "\n",
    "    num_nodes_for_gin = tf.constant([num_nodes], dtype=tf.int32)\n",
    "    \n",
    "    token_ids_for_transformer = tf.expand_dims(token_ids, axis=0) \n",
    "    smiles_mask_for_transformer = tf.expand_dims(smiles_mask, axis=0) \n",
    "    \n",
    "    graph_embedding = gin_encoder((node_features_for_gin, edge_indices_for_gin, num_nodes_for_gin), training=False)\n",
    "    \n",
    "    # smiles_embedding = transformer_encoder((token_ids_for_transformer, smiles_mask_for_transformer), training=False)\n",
    "    smiles_embedding = transformer_encoder((token_ids_for_transformer, smiles_mask_for_transformer), training=False)\n",
    "    \n",
    "    graph_embedding_normalized = tf.linalg.normalize(graph_embedding, axis=1)[0]\n",
    "    smiles_embedding_normalized = tf.linalg.normalize(smiles_embedding, axis=1)[0]\n",
    "\n",
    "    return graph_embedding_normalized, smiles_embedding_normalized\n",
    "\n",
    "\n",
    "#  Test Cases \n",
    "# Choosing a few diverse SMILES strings\n",
    "test_smiles = [\n",
    "    \"CCO\",      # Ethanol (small, simple alcohol)\n",
    "    \"c1ccccc1\", # Benzene (aromatic ring)\n",
    "    \"O=C(Cl)c1ccccc1\", # Benzoyl chloride (more complex, functional group)\n",
    "    \"CC(=O)Oc1ccccc1C(=O)O\", # Aspirin (larger, common drug)\n",
    "    \"C\" # Methane (single atom, check edge case)\n",
    "]\n",
    "\n",
    "# storing embeddings for all test SMILES\n",
    "all_graph_embeddings = []\n",
    "all_smiles_embeddings = []\n",
    "valid_smiles_for_eval = []\n",
    "\n",
    "for smiles in test_smiles:\n",
    "    g_embed, s_embed = get_single_molecule_embeddings(smiles, loaded_gin_encoder, loaded_transformer_encoder)\n",
    "    if g_embed is not None and s_embed is not None:\n",
    "        all_graph_embeddings.append(g_embed)\n",
    "        all_smiles_embeddings.append(s_embed)\n",
    "        valid_smiles_for_eval.append(smiles)\n",
    "    \n",
    "if not valid_smiles_for_eval:\n",
    "    print(\"No valid SMILES were processed for qualitative evaluation.\")\n",
    "else:\n",
    "    all_graph_embeddings_tensor = tf.concat(all_graph_embeddings, axis=0) # (num_valid_smiles, embed_dim)\n",
    "    all_smiles_embeddings_tensor = tf.concat(all_smiles_embeddings, axis=0) # (num_valid_smiles, embed_dim)\n",
    "\n",
    "    print(\"\\n Cosine Similarity Matrix (Graph vs. SMILES) \")\n",
    "    # Calculate cosine similarity matrix: S_ij = sim(graph_i, smiles_j)\n",
    "    similarity_matrix = tf.matmul(all_graph_embeddings_tensor, all_smiles_embeddings_tensor, transpose_b=True).numpy()\n",
    "\n",
    "    print(\"Rows: Graph Embeddings of [SMILES]\\nCols: SMILES Embeddings of [SMILES]\")\n",
    "    # printing column headers (SMILES)\n",
    "    print(\" \" * 10 + \"\".join([f\"{s[:8]:<10}\" for s in valid_smiles_for_eval]))\n",
    "    print(\"-\" * (10 + len(valid_smiles_for_eval) * 10))\n",
    "\n",
    "    for i, smiles_i in enumerate(valid_smiles_for_eval):\n",
    "        row_str = f\"{smiles_i[:8]:<10}\" # Truncating SMILES for display\n",
    "        for j in range(len(valid_smiles_for_eval)):\n",
    "            row_str += f\"{similarity_matrix[i, j]:<10.4f}\"\n",
    "        print(row_str)\n",
    "    print(\"-\" * (10 + len(valid_smiles_for_eval) * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58daf6-40e3-47b0-b7c7-c10cdeecde00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-metal)",
   "language": "python",
   "name": "tf-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
