{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203cabea",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e89b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import Get={'AllBonds': {'bond_types': [], 'bond_stereo': []}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26ddeb",
   "metadata": {},
   "source": [
    "# init TPU (as we are using the Kaggle TPU 4 for faster processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a921b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    print('Not running on TPU, defaulting to GPU/CPU.')\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # Default to GPU or CPU strategy\n",
    "\n",
    "print(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced008e2",
   "metadata": {},
   "source": [
    "# Data Loading and preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda19fa9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "SMILES_FILE_PATH = 'pubchem_smiles_for_pretraining.txt'\n",
    "\n",
    "def load_smiles_data(file_path, num_samples=None):\n",
    "    smiles_list = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if num_samples and i >= num_samples:\n",
    "                break\n",
    "            smiles_list.append(line.strip())\n",
    "    print(f\"Loaded {len(smiles_list)} SMILES strings.\")\n",
    "    return smiles_list\n",
    "\n",
    "\n",
    "# For testing we will use 50,000; 100,000 for quick tests basically.\n",
    "all_smiles = load_smiles_data(SMILES_FILE_PATH, num_samples=50000) \n",
    "\n",
    "# --- SMILES Tokenization ---\n",
    "# A simple character-level tokenizer for demonstration.\n",
    "def build_smiles_vocab(smiles_list, max_vocab_size=None):\n",
    "    all_chars = set()\n",
    "    for smiles in smiles_list:\n",
    "        for char in smiles:\n",
    "            all_chars.add(char)\n",
    "    vocab = sorted(list(all_chars))\n",
    "    # Adding special tokens\n",
    "    vocab = ['<pad>', '<unk>', '<cls>', '<eos>'] + vocab\n",
    "    if max_vocab_size:\n",
    "        vocab = vocab[:max_vocab_size]\n",
    "    char_to_idx = {char: i for i, char in enumerate(vocab)}\n",
    "    idx_to_char = {i: char for i, char in enumerate(vocab)}\n",
    "    print(f\"Built vocabulary of size: {len(vocab)}\")\n",
    "    return vocab, char_to_idx, idx_to_char\n",
    "\n",
    "vocab, char_to_idx, idx_to_char = build_smiles_vocab(all_smiles)\n",
    "VOCAB_SIZE = len(vocab)\n",
    "MAX_SMILES_LEN = 256 # Max sequence length for Transformer.\n",
    "\n",
    "def tokenize_smiles(smiles, char_to_idx, max_len):\n",
    "    \"\"\"Here we basically plan to convert a SMILES string to a sequence of token IDs.\"\"\"\n",
    "    tokens = list(smiles)\n",
    "    indexed_tokens = [char_to_idx.get(char, char_to_idx['<unk>']) for char in tokens]\n",
    "    \n",
    "    # Pad or truncate\n",
    "    if len(indexed_tokens) < max_len:\n",
    "        padded_tokens = indexed_tokens + [char_to_idx['<pad>']] * (max_len - len(indexed_tokens))\n",
    "    else:\n",
    "        padded_tokens = indexed_tokens[:max_len]\n",
    "    return np.array(padded_tokens, dtype=np.int32)\n",
    "\n",
    "def create_smiles_mask(token_ids, pad_token_id):\n",
    "    \"\"\"This will create a boolean mask for padded tokens.\"\"\"\n",
    "    return tf.cast(token_ids == pad_token_id, tf.bool)\n",
    "\n",
    "\n",
    "# --- SMILES to TensorFlow Graph Conversion ---\n",
    "# This is the critical part, transforming SMILES to a graph representation which will be usable by a TensorFlow GNN, specifically sparse tensors for efficiency.\n",
    "\n",
    "# Defining the atom and bond features\n",
    "# These are just example indices for features, along the way we will design specific one-hot encodings or numerical features based on chemical intuition.\n",
    "ATOM_FEATURES_LIST = [\n",
    "    6, 7, 8, 9, 15, 16, 17, 35, 53, # Atomic number (C, N, O, F, P, S, Cl, Br, I)\n",
    "    1, 2, 3, 4, # Degree (number of bonds)\n",
    "    0, 1, 2, 3, 4, # Hybridization (SP, SP2, SP3, SP3D, SP3D2 as ints)\n",
    "    0, 1, # Is aromatic\n",
    "    -1, 0, 1, 2, 3, 4 # Formal charge\n",
    "]\n",
    "NUM_ATOM_FEATURES = len(ATOM_FEATURES_LIST) # we are gonna make it the output dim of our featurizer\n",
    "\n",
    "BOND_FEATURES_LIST = [\n",
    "    Chem.BondType.SINGLE, Chem.BondType.DOUBLE, Chem.BondType.TRIPLE, Chem.BondType.AROMATIC, # Bond types\n",
    "    0, 1 # Is conjugated\n",
    "]\n",
    "NUM_BOND_FEATURES = len(BOND_FEATURES_LIST) # we will also make this the output dim of our featurizer\n",
    "\n",
    "\n",
    "def atom_to_feature_vector(atom):\n",
    "    \"\"\"This will convert an RDKit atom to a feature vector.\"\"\"\n",
    "    features = []\n",
    "    # Atomic number (one-hot or direct embedding if using learned features)\n",
    "    features.append(atom.GetAtomicNum())\n",
    "    features.append(atom.GetDegree())\n",
    "    features.append(int(atom.GetHybridization())) # Convert enum to int\n",
    "    features.append(int(atom.GetIsAromatic()))\n",
    "    features.append(atom.GetFormalCharge())\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "def bond_to_feature_vector(bond):\n",
    "    \"\"\"converting an RDKit bond to a feature vector.\"\"\"\n",
    "    features = []\n",
    "    features.append(int(bond.GetBondType()))\n",
    "    features.append(int(bond.GetIsConjugated()))\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "def smiles_to_tf_graph(smiles_string):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to TensorFlow graph components:\n",
    "    node_features, edge_indices, and num_nodes.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    if mol is None:\n",
    "        return None, None, None\n",
    "\n",
    "    # Getting node features\n",
    "    node_features = [atom_to_feature_vector(atom) for atom in mol.GetAtoms()]\n",
    "    if not node_features: \n",
    "        return None, None, None\n",
    "    node_features = np.array(node_features, dtype=np.float32)\n",
    "    num_nodes = len(node_features)\n",
    "\n",
    "    # Get edge indices (like in the adjacency list format)\n",
    "    # RDKit's GetBonds() already gives each bond once\n",
    "    edge_indices = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_indices.append([i, j])\n",
    "        edge_indices.append([j, i])  # Adding the reverse edge incase for undirected graph\n",
    "\n",
    "    if not edge_indices: # for handling the single atom molecules or molecules with no bonds\n",
    "        # For a single node we will create a self-loop so it ks not isolated in the graph\n",
    "        if num_nodes == 1:\n",
    "            edge_indices = [[0, 0]]\n",
    "        else:\n",
    "            return node_features, tf.zeros((0, 2), dtype=tf.int32), num_nodes # No edges\n",
    "\n",
    "    edge_indices = np.array(edge_indices, dtype=np.int32)\n",
    "\n",
    "    return node_features, edge_indices, num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6f6e4",
   "metadata": {},
   "source": [
    "# --- Creating tf.data.Dataset for TPU ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb21682",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# We are Defining the featurization function for the dataset map operation\n",
    "def featurize_smiles_and_graph(smiles_string):\n",
    "    token_ids = tokenize_smiles(smiles_string.numpy().decode('utf-8'), char_to_idx, MAX_SMILES_LEN)\n",
    "    mask = create_smiles_mask(token_ids, char_to_idx['<pad>'])\n",
    "\n",
    "    node_features, edge_indices, num_nodes = smiles_to_tf_graph(smiles_string.numpy().decode('utf-8'))\n",
    "\n",
    "    # Handling the cases where graph conversion fails (e.g., invalid smiles)\n",
    "    if node_features is None:\n",
    "        # Return dummy values that will be filtered out later if needed, or ideally, pre-filter your SMILES list to remove unconvertible ones.\n",
    "        # For simplicity here, we'll return a minimal valid structure for filtering.\n",
    "        dummy_node_features = tf.zeros((1, NUM_ATOM_FEATURES), dtype=tf.float32)\n",
    "        dummy_edge_indices = tf.zeros((0, 2), dtype=tf.int32)\n",
    "        dummy_num_nodes = tf.constant(0, dtype=tf.int32)\n",
    "        return dummy_node_features, dummy_edge_indices, dummy_num_nodes, token_ids, mask\n",
    "    \n",
    "    # We will ensure node_features has consistent shape by padding if necessary for batching\n",
    "    # It assumes a maximum number of nodes in any graph.\n",
    "    MAX_NODES = 100 \n",
    "    padded_node_features = tf.pad(node_features, [[0, MAX_NODES - num_nodes], [0, 0]])\n",
    "    \n",
    "    return (tf.constant(padded_node_features, dtype=tf.float32),\n",
    "            tf.constant(edge_indices, dtype=tf.int32),\n",
    "            tf.constant(num_nodes, dtype=tf.int32),\n",
    "            tf.constant(token_ids, dtype=tf.int32),\n",
    "            tf.constant(mask, dtype=tf.bool))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_smiles)\n",
    "\n",
    "# Mapping the featurization function by using tf.py_function for non-TF operations (RDKit)\n",
    "dataset = dataset.map(lambda x: tf.py_function(\n",
    "    featurize_smiles_and_graph,\n",
    "    inp=[x],\n",
    "    Tout=(tf.float32, tf.int32, tf.int32, tf.int32, tf.bool)\n",
    "), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Filtering out the failed conversions\n",
    "dataset = dataset.filter(lambda node_feat, edge_idx, num_nodes, token_ids, mask: num_nodes > 0)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64 \n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "padded_shapes = (\n",
    "    tf.TensorShape([MAX_NODES, NUM_ATOM_FEATURES]), # node_features\n",
    "    tf.TensorShape([None, 2]), # edge_indices (variable length per graph in batch)\n",
    "    tf.TensorShape([]),        # num_nodes (scalar per graph)\n",
    "    tf.TensorShape([MAX_SMILES_LEN]), # token_ids\n",
    "    tf.TensorShape([MAX_SMILES_LEN])  # mask\n",
    ")\n",
    "padding_values = (\n",
    "    tf.constant(0.0, dtype=tf.float32), # node_features padding\n",
    "    tf.constant(0, dtype=tf.int32),     # edge_indices padding\n",
    "    tf.constant(0, dtype=tf.int32),     # num_nodes padding (not strictly needed as it's a scalar per element)\n",
    "    tf.constant(char_to_idx['<pad>'], dtype=tf.int32), # token_ids padding\n",
    "    tf.constant(True, dtype=tf.bool)    # mask padding\n",
    ")\n",
    "\n",
    "dataset = dataset.cache() # We are Caching data after featurization for faster epochs\n",
    "dataset = dataset.shuffle(buffer_size=10000) \n",
    "dataset = dataset.padded_batch(GLOBAL_BATCH_SIZE, padded_shapes=padded_shapes, padding_values=padding_values, drop_remainder=True)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3cc0f8",
   "metadata": {},
   "source": [
    "# --- Model Architecture (TensorFlow/Keras) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7bcbe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# GIN Layer (as a Custom Keras Layer) we are doing it as this implements the core GIN aggregation as a Keras layer suitable for sparse tensors and TPU\n",
    "class GINLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, activation=None, **kwargs):\n",
    "        super(GINLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(output_dim, activation='relu'),\n",
    "            layers.Dense(output_dim)\n",
    "        ])\n",
    "        self.epsilon = self.add_weight(name='epsilon', shape=(),\n",
    "                                       initializer=keras.initializers.Constant(0.0),\n",
    "                                       trainable=True)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_features, edge_indices_batch, num_nodes_batch = inputs\n",
    "        \n",
    "        edge_values = tf.ones(tf.shape(edge_indices_batch)[0], dtype=tf.float32)\n",
    "        \n",
    "        total_nodes_in_batch = tf.shape(node_features)[0]\n",
    "        adj_shape = tf.cast([total_nodes_in_batch, total_nodes_in_batch], dtype=tf.int64)\n",
    "\n",
    "        adj_sparse = tf.sparse.SparseTensor(indices=tf.cast(edge_indices_batch, tf.int64),\n",
    "                                            values=edge_values,\n",
    "                                            dense_shape=adj_shape)\n",
    "        \n",
    "        # Sum of neighbor features: (A * H)\n",
    "        neighbor_sum = tf.sparse.sparse_dense_matmul(adj_sparse, node_features)\n",
    "\n",
    "        # GIN update: MLP((1 + epsilon) * H + Sum(Neighbors))\n",
    "        combined_features = (1 + self.epsilon) * node_features + neighbor_sum\n",
    "        output = self.mlp(combined_features)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0][0], self.output_dim # (batch_size * max_nodes_per_graph, output_dim)\n",
    "\n",
    "class GINEncoder(keras.Model):\n",
    "    def __init__(self, num_layers, hidden_dim, **kwargs):\n",
    "        super(GINEncoder, self).__init__(**kwargs)\n",
    "        self.gin_layers = []\n",
    "        for i in range(num_layers):\n",
    "            self.gin_layers.append(GINLayer(hidden_dim, activation='relu' if i < num_layers - 1 else None))\n",
    "            self.gin_layers.append(layers.BatchNormalization()) # we are adding BatchNorm\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_features, edge_indices, num_nodes = inputs # num_nodes is list of actual counts per graph\n",
    "\n",
    "        x = node_features\n",
    "        for i, gin_layer in enumerate(self.gin_layers):\n",
    "            if isinstance(gin_layer, GINLayer):\n",
    "                x = gin_layer((x, edge_indices, num_nodes))\n",
    "            else: # in the case ofBatchNormalization\n",
    "                x = gin_layer(x)\n",
    "        \n",
    "        # Global pooling (Sum Pooling for GIN)\n",
    "        batch_size = tf.shape(node_features)[0] // MAX_NODES \n",
    "        x_reshaped = tf.reshape(x, (batch_size, MAX_NODES, hidden_dim))\n",
    "        \n",
    "        # Mask out padded nodes before summing\n",
    "       \n",
    "        # For now, let's use a dummy global pooling, we are gonna refine it later.\n",
    "        \n",
    "        batch_size = tf.shape(node_features)[0] // MAX_NODES # This assumes exact padding\n",
    "        \n",
    "        # Reshape to (batch_size, MAX_NODES, hidden_dim)\n",
    "        x_reshaped = tf.reshape(x, (batch_size, MAX_NODES, hidden_dim))\n",
    "        \n",
    "        # Creating a mask for valid nodes in each graph\n",
    "        # `num_nodes` is the actual number of nodes *before* padding for each graph in the batch (GLOBAL_BATCH_SIZE,)\n",
    "        \n",
    "        # We use `tf.sequence_mask` to create a boolean mask\n",
    "        sequence_mask = tf.sequence_mask(num_nodes, maxlen=MAX_NODES, dtype=tf.float32) # (BATCH_SIZE, MAX_NODES)\n",
    "        sequence_mask = tf.expand_dims(sequence_mask, axis=-1) # (BATCH_SIZE, MAX_NODES, 1)\n",
    "        \n",
    "        # Apply mask and sum\n",
    "        masked_x = x_reshaped * sequence_mask\n",
    "        graph_embedding = tf.reduce_sum(masked_x, axis=1) # Sum pooling\n",
    "        \n",
    "        return graph_embedding \n",
    "\n",
    "class TransformerEncoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, max_seq_len, dropout_rate=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.token_embedding = layers.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_embedding = self.add_weight(\n",
    "            name=\"pos_embed\",\n",
    "            shape=(1, max_seq_len, embed_dim),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        self.encoder_layers = []\n",
    "        for _ in range(num_layers):\n",
    "            self.encoder_layers.append([\n",
    "                layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout_rate),\n",
    "                layers.LayerNormalization(epsilon=1e-6),\n",
    "                layers.Dense(embed_dim * 4, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "                layers.LayerNormalization(epsilon=1e-6),\n",
    "            ])\n",
    "        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        token_ids, padding_mask = inputs # padding_mask is boolean (True for padded)\n",
    "        \n",
    "        x = self.token_embedding(token_ids)\n",
    "        x = x + self.positional_embedding[:, :tf.shape(x)[1], :]\n",
    "\n",
    "        for i, (attention, norm1, ff_dense1, ff_dense2, norm2) in enumerate(self.encoder_layers):\n",
    "            # Attention block\n",
    "            attn_output = attention(x, x, attention_mask=padding_mask, training=training)\n",
    "            x = norm1(x + attn_output) # Add & Norm\n",
    "\n",
    "            # Feed-forward block\n",
    "            ff_output = ff_dense2(ff_dense1(x))\n",
    "            x = norm2(x + ff_output) # Add & Norm\n",
    "        \n",
    "        # Global pooling: mask out padded tokens before mean pooling\n",
    "\n",
    "        expanded_padding_mask = tf.cast(tf.expand_dims(padding_mask, axis=-1), dtype=x.dtype)\n",
    "        \n",
    "        # Invert the mask logic: 1.0 for non-padded, 0.0 for padded\n",
    "        non_padded_mask = 1.0 - expanded_padding_mask\n",
    "        \n",
    "        # Apply mask: so we will set padded embeddings to 0\n",
    "        x_masked = x * non_padded_mask\n",
    "        \n",
    "        # Sum along sequence dimension\n",
    "        sum_embeddings = tf.reduce_sum(x_masked, axis=1)\n",
    "        \n",
    "        # Counting non-padded elements per sequence\n",
    "        non_padded_len = tf.reduce_sum(non_padded_mask, axis=1)\n",
    "        \n",
    "        # Mean pooling (also avoiding division by zero for fully padded sequences)\n",
    "        smiles_embedding = sum_embeddings / (non_padded_len + 1e-9) # Adding epsilon to avoid div by zero\n",
    "        \n",
    "        return self.final_norm(smiles_embedding)\n",
    "\n",
    "\n",
    "class ProjectionHead(keras.Model):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=256, **kwargs):\n",
    "        super(ProjectionHead, self).__init__(**kwargs)\n",
    "        self.net = keras.Sequential([\n",
    "            layers.Dense(hidden_dim, activation='relu'),\n",
    "            layers.Dense(output_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class GRASPModel(keras.Model):\n",
    "    def __init__(self, gin_config, transformer_config, projection_dim, **kwargs):\n",
    "        super(GRASPModel, self).__init__(**kwargs)\n",
    "        self.gin_encoder = GINEncoder(**gin_config)\n",
    "        self.transformer_encoder = TransformerEncoder(**transformer_config)\n",
    "        \n",
    "        self.graph_projection_head = ProjectionHead(gin_config['hidden_dim'], projection_dim)\n",
    "        self.smiles_projection_head = ProjectionHead(transformer_config['embed_dim'], projection_dim)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Inputs are unpacked from the dataset tuple\n",
    "        node_features, edge_indices, num_nodes, token_ids, smiles_mask = inputs\n",
    "        \n",
    "        # Encoding graphs\n",
    "        graph_embeddings_raw = self.gin_encoder((node_features, edge_indices, num_nodes), training=training)\n",
    "        graph_embeddings_projected = self.graph_projection_head(graph_embeddings_raw, training=training)\n",
    "\n",
    "        # Encoding SMILES\n",
    "        smiles_embeddings_raw = self.transformer_encoder((token_ids, smiles_mask), training=training)\n",
    "        smiles_embeddings_projected = self.smiles_projection_head(smiles_embeddings_raw, training=training)\n",
    "\n",
    "        # Applying L2 normalization to projected embeddings for InfoNCE loss\n",
    "        graph_embeddings_projected = tf.linalg.normalize(graph_embeddings_projected, axis=1)[0]\n",
    "        smiles_embeddings_projected = tf.linalg.normalize(smiles_embeddings_projected, axis=1)[0]\n",
    "\n",
    "        return graph_embeddings_projected, smiles_embeddings_projected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2782bc8a",
   "metadata": {},
   "source": [
    "# --- Contrastive Loss (InfoNCE) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09af71b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class InfoNCELoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=0.07, name='info_nce_loss', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, graph_embeddings, smiles_embeddings):\n",
    "\n",
    "        # Cosine similarity matrix (logits)\n",
    "        # S_ij = sim(g_i, s_j)\n",
    "        logits = tf.matmul(graph_embeddings, smiles_embeddings, transpose_b=True) / self.temperature\n",
    "        \n",
    "        # Creating labels: diagonal elements are positive pairs\n",
    "        batch_size = tf.shape(logits)[0]\n",
    "        labels = tf.eye(batch_size) # (batch_size, batch_size)\n",
    "\n",
    "        # Calculating cross-entropy for graph->SMILES and SMILES->graph\n",
    "        # loss_g_s: how well graph embeddings predict their corresponding SMILES\n",
    "        loss_g_s = tf.keras.losses.categorical_crossentropy(labels, logits, from_logits=True)\n",
    "        \n",
    "        # loss_s_g: how well SMILES embeddings predict their corresponding graphs\n",
    "        loss_s_g = tf.keras.losses.categorical_crossentropy(labels, tf.transpose(logits), from_logits=True)\n",
    "\n",
    "        # Total loss is the average of both directions\n",
    "        total_loss = (loss_g_s + loss_s_g) / 2\n",
    "        \n",
    "        # Reduce mean over the batch\n",
    "        return tf.reduce_mean(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91840c15",
   "metadata": {},
   "source": [
    "# --- Training Loop ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fc2e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 128 # Dimension of the shared embedding space\n",
    "HIDDEN_DIM_GIN = 256 \n",
    "NUM_GIN_LAYERS = 3   \n",
    "EMBED_DIM_TRANSFORMER = 256 \n",
    "NUM_TRANSFORMER_HEADS = 8\n",
    "NUM_TRANSFORMER_LAYERS = 3\n",
    "\n",
    "gin_config = {\n",
    "    'num_layers': NUM_GIN_LAYERS,\n",
    "    'hidden_dim': HIDDEN_DIM_GIN,\n",
    "    # Atom features from featurization. This is the input_dim for the first GIN layer.\n",
    "    # It must match the output of `atom_to_feature_vector`.\n",
    "    'num_node_features': len(atom_to_feature_vector(Chem.Atom(6))) # Using a dummy atom to get feature count\n",
    "}\n",
    "\n",
    "transformer_config = {\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'embed_dim': EMBED_DIM_TRANSFORMER,\n",
    "    'num_heads': NUM_TRANSFORMER_HEADS,\n",
    "    'num_layers': NUM_TRANSFORMER_LAYERS,\n",
    "    'max_seq_len': MAX_SMILES_LEN\n",
    "}\n",
    "\n",
    "# Defining the training step function\n",
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        graph_embeddings, smiles_embeddings = model(inputs, training=True)\n",
    "        loss = info_nce_loss(graph_embeddings, smiles_embeddings)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Instantiating model, loss, and optimizer within the TPU strategy scope\n",
    "with strategy.scope():\n",
    "    model = GRASPModel(gin_config, transformer_config, PROJECTION_DIM)\n",
    "    info_nce_loss = InfoNCELoss(temperature=0.07) # Adjust temperature as needed\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=info_nce_loss)\n",
    "\n",
    "EPOCHS = 5 \n",
    "steps_per_epoch = tf.data.experimental.cardinality(dataset).numpy()\n",
    "\n",
    "print(f\"\\nStarting pre-training for {EPOCHS} epochs...\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch_inputs in dataset:\n",
    "        per_replica_losses = strategy.run(train_step, args=(batch_inputs,))\n",
    "        batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "        total_loss += batch_loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        if num_batches % 10 == 0:\n",
    "            print(f\"  Batch {num_batches}/{steps_per_epoch}, Loss: {batch_loss:.4f}\", end='\\r')\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch + 1} finished. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\nPre-training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53c3b9",
   "metadata": {},
   "source": [
    "# --- Saving the model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd015d93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# To save just the encoders:\n",
    "# tf.saved_model.save(model.gin_encoder, 'gin_encoder_pretrained')\n",
    "# tf.saved_model.save(model.transformer_encoder, 'transformer_encoder_pretrained')\n",
    "# print(\"Encoders saved.\")\n",
    "\n",
    "\n",
    "model.save('grasp_pretrained_model')\n",
    "print(\"Model saved to 'grasp_pretrained_model' directory.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
