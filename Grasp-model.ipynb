{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12249061,"sourceType":"datasetVersion","datasetId":7718046}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"37bd6b3a-cbe9-4166-ad2a-a4399cfd9de1","cell_type":"code","source":"!pip install rdkit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:21.269280Z","iopub.execute_input":"2025-06-22T17:45:21.269623Z","iopub.status.idle":"2025-06-22T17:45:24.741819Z","shell.execute_reply.started":"2025-06-22T17:45:21.269589Z","shell.execute_reply":"2025-06-22T17:45:24.736839Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rdkit in /usr/local/lib/python3.10/site-packages (2025.3.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (2.0.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (11.2.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":10},{"id":"0f6aad75-9f70-4dbf-8a5d-35350d245adb","cell_type":"code","source":"# Importing Libraries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.743095Z","iopub.execute_input":"2025-06-22T17:45:24.743360Z","iopub.status.idle":"2025-06-22T17:45:24.752842Z","shell.execute_reply.started":"2025-06-22T17:45:24.743328Z","shell.execute_reply":"2025-06-22T17:45:24.748510Z"}},"outputs":[],"execution_count":11},{"id":"b81e89b2","cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom rdkit import Chem","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.754584Z","iopub.execute_input":"2025-06-22T17:45:24.754931Z","iopub.status.idle":"2025-06-22T17:45:24.768448Z","shell.execute_reply.started":"2025-06-22T17:45:24.754910Z","shell.execute_reply":"2025-06-22T17:45:24.762087Z"}},"outputs":[],"execution_count":12},{"id":"bc26ddeb","cell_type":"markdown","source":"# init TPU (as we are using the Kaggle TPU 4 for faster processing)","metadata":{}},{"id":"b0a921b5","cell_type":"code","source":"\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n    print('Not running on TPU, defaulting to GPU/CPU.')\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # Default to GPU or CPU strategy\n\nprint(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.770456Z","iopub.execute_input":"2025-06-22T17:45:24.770683Z","iopub.status.idle":"2025-06-22T17:45:24.780979Z","shell.execute_reply.started":"2025-06-22T17:45:24.770661Z","shell.execute_reply":"2025-06-22T17:45:24.776806Z"}},"outputs":[{"name":"stdout","text":"Not running on TPU, defaulting to GPU/CPU.\nNumber of accelerators: 1\n","output_type":"stream"}],"execution_count":13},{"id":"ced008e2","cell_type":"markdown","source":"# Data Loading and preprocesing","metadata":{}},{"id":"bda19fa9","cell_type":"code","source":"SMILES_FILE_PATH = '/kaggle/input/pubchem-smiles-for-pretraining/pubchem_smiles_for_pretraining.txt'\n\ndef load_smiles_data(file_path, num_samples=None):\n    smiles_list = []\n    with open(file_path, 'r') as f:\n        for i, line in enumerate(f):\n            if num_samples and i >= num_samples:\n                break\n            smiles_list.append(line.strip())\n    print(f\"Loaded {len(smiles_list)} SMILES strings.\")\n    return smiles_list\n\n\n# For testing we will use 50,000; 100,000 for quick tests basically.\nall_smiles = load_smiles_data(SMILES_FILE_PATH, num_samples=50000) \n\n# --- SMILES Tokenization ---\n# A simple character-level tokenizer for demonstration.\ndef build_smiles_vocab(smiles_list, max_vocab_size=None):\n    all_chars = set()\n    for smiles in smiles_list:\n        for char in smiles:\n            all_chars.add(char)\n    vocab = sorted(list(all_chars))\n    # Adding special tokens\n    vocab = ['<pad>', '<unk>', '<cls>', '<eos>'] + vocab\n    if max_vocab_size:\n        vocab = vocab[:max_vocab_size]\n    char_to_idx = {char: i for i, char in enumerate(vocab)}\n    idx_to_char = {i: char for i, char in enumerate(vocab)}\n    print(f\"Built vocabulary of size: {len(vocab)}\")\n    return vocab, char_to_idx, idx_to_char\n\nvocab, char_to_idx, idx_to_char = build_smiles_vocab(all_smiles)\nVOCAB_SIZE = len(vocab)\nMAX_SMILES_LEN = 256 # Max sequence length for Transformer.\nMAX_NODES = 100      # Maximum number of nodes in any graph in a batch. Adjust based on data.\n\ndef tokenize_smiles(smiles, char_to_idx, max_len):\n    \"\"\"Here we basically plan to convert a SMILES string to a sequence of token IDs.\"\"\"\n    tokens = list(smiles)\n    indexed_tokens = [char_to_idx.get(char, char_to_idx['<unk>']) for char in tokens]\n    \n    # Pad or truncate\n    if len(indexed_tokens) < max_len:\n        padded_tokens = indexed_tokens + [char_to_idx['<pad>']] * (max_len - len(indexed_tokens))\n    else:\n        padded_tokens = indexed_tokens[:max_len]\n    return np.array(padded_tokens, dtype=np.int32)\n\ndef create_smiles_mask(token_ids, pad_token_id):\n    \"\"\"This will create a boolean mask for padded tokens.\"\"\"\n    return tf.cast(token_ids == pad_token_id, tf.bool)\n\n\n# --- SMILES to TensorFlow Graph Conversion ---\n# This is the critical part, transforming SMILES to a graph representation which will be usable by a TensorFlow GNN, specifically sparse tensors for efficiency.\n\n# Defining the atom and bond features\n# These are just example indices for features, along the way we will design specific one-hot encodings or numerical features based on chemical intuition.\nATOM_FEATURES_LIST = [\n    6, 7, 8, 9, 15, 16, 17, 35, 53, # Atomic number (C, N, O, F, P, S, Cl, Br, I)\n    1, 2, 3, 4, # Degree (number of bonds)\n    0, 1, 2, 3, 4, # Hybridization (SP, SP2, SP3, SP3D, SP3D2 as ints)\n    0, 1, # Is aromatic\n    -1, 0, 1, 2, 3, 4 # Formal charge\n]\nNUM_ATOM_FEATURES = len(ATOM_FEATURES_LIST) # we are gonna make it the output dim of our featurizer\n\nBOND_FEATURES_LIST = [\n    Chem.BondType.SINGLE, Chem.BondType.DOUBLE, Chem.BondType.TRIPLE, Chem.BondType.AROMATIC, # Bond types\n    0, 1 # Is conjugated\n]\nNUM_BOND_FEATURES = len(BOND_FEATURES_LIST) # we will also make this the output dim of our featurizer\n\n\ndef atom_to_feature_vector(atom):\n    \"\"\"This will convert an RDKit atom to a feature vector.\"\"\"\n    features = []\n    # Atomic number (one-hot or direct embedding if using learned features)\n    features.append(atom.GetAtomicNum())\n    features.append(atom.GetDegree())\n    features.append(int(atom.GetHybridization())) # Convert enum to int\n    features.append(int(atom.GetIsAromatic()))\n    features.append(atom.GetFormalCharge())\n    return np.array(features, dtype=np.float32)\n\ndef bond_to_feature_vector(bond):\n    \"\"\"converting an RDKit bond to a feature vector.\"\"\"\n    features = []\n    features.append(int(bond.GetBondType()))\n    features.append(int(bond.GetIsConjugated()))\n    return np.array(features, dtype=np.float32)\n\ndef smiles_to_tf_graph(smiles_string):\n    \"\"\"\n    Converts a SMILES string to TensorFlow graph components:\n    node_features, edge_indices, and num_nodes.\n    \"\"\"\n    mol = Chem.MolFromSmiles(smiles_string)\n    if mol is None:\n        return None, None, None\n\n    # Getting node features\n    node_features = [atom_to_feature_vector(atom) for atom in mol.GetAtoms()]\n    if not node_features: \n        return None, None, None\n    node_features = np.array(node_features, dtype=np.float32)\n    num_nodes = len(node_features)\n\n    # Get edge indices (like in the adjacency list format)\n    # RDKit's GetBonds() already gives each bond once\n    edge_indices = []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_indices.append([i, j])\n        edge_indices.append([j, i])  # Adding the reverse edge incase for undirected graph\n\n    if not edge_indices: # for handling the single atom molecules or molecules with no bonds\n        # For a single node we will create a self-loop so it ks not isolated in the graph\n        if num_nodes == 1:\n            edge_indices = [[0, 0]]\n        else:\n            return node_features, tf.zeros((0, 2), dtype=tf.int32), num_nodes # No edges\n\n    edge_indices = np.array(edge_indices, dtype=np.int32)\n\n    return node_features, edge_indices, num_nodes","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:50:42.535472Z","iopub.execute_input":"2025-06-22T17:50:42.535814Z","iopub.status.idle":"2025-06-22T17:50:42.680371Z","shell.execute_reply.started":"2025-06-22T17:50:42.535787Z","shell.execute_reply":"2025-06-22T17:50:42.675049Z"}},"outputs":[{"name":"stdout","text":"Loaded 50000 SMILES strings.\nBuilt vocabulary of size: 71\n","output_type":"stream"}],"execution_count":18},{"id":"dfb6f6e4","cell_type":"markdown","source":"# --- Creating tf.data.Dataset for TPU ---","metadata":{}},{"id":"9bb21682","cell_type":"code","source":"\n# We are Defining the featurization function for the dataset map operation\ndef featurize_smiles_and_graph(smiles_string):\n    token_ids = tokenize_smiles(smiles_string.numpy().decode('utf-8'), char_to_idx, MAX_SMILES_LEN)\n    mask = create_smiles_mask(token_ids, char_to_idx['<pad>'])\n\n    node_features, edge_indices, num_nodes = smiles_to_tf_graph(smiles_string.numpy().decode('utf-8'))\n\n    # Handling the cases where graph conversion fails (e.g., invalid smiles)\n    if node_features is None:\n        # Return dummy values that will be filtered out later if needed, or ideally, pre-filter your SMILES list to remove unconvertible ones.\n        # For simplicity here, we'll return a minimal valid structure for filtering.\n        dummy_node_features = tf.zeros((1, NUM_ATOM_FEATURES), dtype=tf.float32)\n        dummy_edge_indices = tf.zeros((0, 2), dtype=tf.int32)\n        dummy_num_nodes = tf.constant(0, dtype=tf.int32)\n        return dummy_node_features, dummy_edge_indices, dummy_num_nodes, token_ids, mask\n    \n    # We will ensure node_features has consistent shape by padding if necessary for batching\n    # It assumes a maximum number of nodes in any graph.\n    padded_node_features = tf.pad(node_features, [[0, MAX_NODES - num_nodes], [0, 0]])\n    \n    return (tf.constant(padded_node_features, dtype=tf.float32),\n            tf.constant(edge_indices, dtype=tf.int32),\n            tf.constant(num_nodes, dtype=tf.int32),\n            tf.constant(token_ids, dtype=tf.int32),\n            tf.constant(mask, dtype=tf.bool))\n\ndataset = tf.data.Dataset.from_tensor_slices(all_smiles)\n\n# Mapping the featurization function by using tf.py_function for non-TF operations (RDKit)\ndataset = dataset.map(lambda x: tf.py_function(\n    featurize_smiles_and_graph,\n    inp=[x],\n    Tout=(tf.float32, tf.int32, tf.int32, tf.int32, tf.bool)\n), num_parallel_calls=tf.data.AUTOTUNE)\n\n# Filtering out the failed conversions\ndataset = dataset.filter(lambda node_feat, edge_idx, num_nodes, token_ids, mask: num_nodes > 0)\n\nBATCH_SIZE_PER_REPLICA = 64 \nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\npadded_shapes = (\n    tf.TensorShape([MAX_NODES, NUM_ATOM_FEATURES]), # node_features\n    tf.TensorShape([None, 2]), # edge_indices (variable length per graph in batch)\n    tf.TensorShape([]),        # num_nodes (scalar per graph)\n    tf.TensorShape([MAX_SMILES_LEN]), # token_ids\n    tf.TensorShape([MAX_SMILES_LEN])  # mask\n)\npadding_values = (\n    tf.constant(0.0, dtype=tf.float32), # node_features padding\n    tf.constant(0, dtype=tf.int32),     # edge_indices padding\n    tf.constant(0, dtype=tf.int32),     # num_nodes padding (not strictly needed as it's a scalar per element)\n    tf.constant(char_to_idx['<pad>'], dtype=tf.int32), # token_ids padding\n    tf.constant(True, dtype=tf.bool)    # mask padding\n)\n\ndataset = dataset.cache() # We are Caching data after featurization for faster epochs\ndataset = dataset.shuffle(buffer_size=10000) \ndataset = dataset.padded_batch(GLOBAL_BATCH_SIZE, padded_shapes=padded_shapes, padding_values=padding_values, drop_remainder=True)\ndataset = dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:50:44.387026Z","iopub.execute_input":"2025-06-22T17:50:44.387363Z","iopub.status.idle":"2025-06-22T17:50:44.533085Z","shell.execute_reply.started":"2025-06-22T17:50:44.387335Z","shell.execute_reply":"2025-06-22T17:50:44.528370Z"}},"outputs":[],"execution_count":19},{"id":"ce3cc0f8","cell_type":"markdown","source":"# --- Model Architecture (TensorFlow/Keras) ---","metadata":{}},{"id":"63e7bcbe","cell_type":"code","source":"# GIN Layer (as a Custom Keras Layer) we are doing it as this implements the core GIN aggregation as a Keras layer suitable for sparse tensors and TPU\nclass GINLayer(layers.Layer):\n    def __init__(self, output_dim, activation=None, **kwargs):\n        super(GINLayer, self).__init__(**kwargs)\n        self.output_dim = output_dim\n        self.mlp = keras.Sequential([\n            layers.Dense(output_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n        self.epsilon = self.add_weight(name='epsilon', shape=(),\n                                       initializer=keras.initializers.Constant(0.0),\n                                       trainable=True)\n        self.activation = keras.activations.get(activation)\n\n    def call(self, inputs):\n        node_features, edge_indices_batch, num_nodes_batch = inputs\n        \n        edge_values = tf.ones(tf.shape(edge_indices_batch)[0], dtype=tf.float32)\n        \n        total_nodes_in_batch = tf.shape(node_features)[0]\n        adj_shape = tf.cast([total_nodes_in_batch, total_nodes_in_batch], dtype=tf.int64)\n\n        adj_sparse = tf.sparse.SparseTensor(indices=tf.cast(edge_indices_batch, tf.int64),\n                                            values=edge_values,\n                                            dense_shape=adj_shape)\n        \n        # Sum of neighbor features: (A * H)\n        neighbor_sum = tf.sparse.sparse_dense_matmul(adj_sparse, node_features)\n\n        # GIN update: MLP((1 + epsilon) * H + Sum(Neighbors))\n        combined_features = (1 + self.epsilon) * node_features + neighbor_sum\n        output = self.mlp(combined_features)\n\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0][0], self.output_dim # (batch_size * max_nodes_per_graph, output_dim)\n\nclass GINEncoder(keras.Model):\n    def __init__(self, num_layers, hidden_dim, **kwargs):\n        super(GINEncoder, self).__init__(**kwargs)\n        self.gin_layers = []\n        for i in range(num_layers):\n            self.gin_layers.append(GINLayer(hidden_dim, activation='relu' if i < num_layers - 1 else None))\n            self.gin_layers.append(layers.BatchNormalization()) # we are adding BatchNorm\n\n    def call(self, inputs):\n        node_features, edge_indices, num_nodes = inputs # num_nodes is list of actual counts per graph\n\n        x = node_features\n        for i, gin_layer in enumerate(self.gin_layers):\n            if isinstance(gin_layer, GINLayer):\n                x = gin_layer((x, edge_indices, num_nodes))\n            else: # in the case ofBatchNormalization\n                x = gin_layer(x)\n        \n        # Global pooling (Sum Pooling for GIN)\n        batch_size = tf.shape(node_features)[0] // MAX_NODES \n        x_reshaped = tf.reshape(x, (batch_size, MAX_NODES, hidden_dim))\n        \n        # Mask out padded nodes before summing\n       \n        # For now, let's use a dummy global pooling, we are gonna refine it later.\n        \n        batch_size = tf.shape(node_features)[0] // MAX_NODES # This assumes exact padding\n        \n        # Reshape to (batch_size, MAX_NODES, hidden_dim)\n        x_reshaped = tf.reshape(x, (batch_size, MAX_NODES, hidden_dim))\n        \n        # Creating a mask for valid nodes in each graph\n        # `num_nodes` is the actual number of nodes *before* padding for each graph in the batch (GLOBAL_BATCH_SIZE,)\n        \n        # We use `tf.sequence_mask` to create a boolean mask\n        sequence_mask = tf.sequence_mask(num_nodes, maxlen=MAX_NODES, dtype=tf.float32) # (BATCH_SIZE, MAX_NODES)\n        sequence_mask = tf.expand_dims(sequence_mask, axis=-1) # (BATCH_SIZE, MAX_NODES, 1)\n        \n        # Apply mask and sum\n        masked_x = x_reshaped * sequence_mask\n        graph_embedding = tf.reduce_sum(masked_x, axis=1) # Sum pooling\n        \n        return graph_embedding \n\nclass TransformerEncoder(keras.Model):\n    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, max_seq_len, dropout_rate=0.1, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.token_embedding = layers.Embedding(vocab_size, embed_dim)\n        self.positional_embedding = self.add_weight(\n            name=\"pos_embed\",\n            shape=(1, max_seq_len, embed_dim),\n            initializer=\"random_normal\",\n            trainable=True\n        )\n\n        self.encoder_layers = []\n        for _ in range(num_layers):\n            self.encoder_layers.append([\n                layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout_rate),\n                layers.LayerNormalization(epsilon=1e-6),\n                layers.Dense(embed_dim * 4, activation=\"relu\"),\n                layers.Dense(embed_dim),\n                layers.LayerNormalization(epsilon=1e-6),\n            ])\n        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, inputs, training=False, mask=None):\n        token_ids, padding_mask = inputs # padding_mask is boolean (True for padded)\n        \n        x = self.token_embedding(token_ids)\n        x = x + self.positional_embedding[:, :tf.shape(x)[1], :]\n\n        for i, (attention, norm1, ff_dense1, ff_dense2, norm2) in enumerate(self.encoder_layers):\n            # Attention block\n            attn_output = attention(x, x, attention_mask=padding_mask, training=training)\n            x = norm1(x + attn_output) # Add & Norm\n\n            # Feed-forward block\n            ff_output = ff_dense2(ff_dense1(x))\n            x = norm2(x + ff_output) # Add & Norm\n        \n        # Global pooling: mask out padded tokens before mean pooling\n\n        expanded_padding_mask = tf.cast(tf.expand_dims(padding_mask, axis=-1), dtype=x.dtype)\n        \n        # Invert the mask logic: 1.0 for non-padded, 0.0 for padded\n        non_padded_mask = 1.0 - expanded_padding_mask\n        \n        # Apply mask: so we will set padded embeddings to 0\n        x_masked = x * non_padded_mask\n        \n        # Sum along sequence dimension\n        sum_embeddings = tf.reduce_sum(x_masked, axis=1)\n        \n        # Counting non-padded elements per sequence\n        non_padded_len = tf.reduce_sum(non_padded_mask, axis=1)\n        \n        # Mean pooling (also avoiding division by zero for fully padded sequences)\n        smiles_embedding = sum_embeddings / (non_padded_len + 1e-9) # Adding epsilon to avoid div by zero\n        \n        return self.final_norm(smiles_embedding)\n\n\nclass ProjectionHead(keras.Model):\n    def __init__(self, input_dim, output_dim, hidden_dim=256, **kwargs):\n        super(ProjectionHead, self).__init__(**kwargs)\n        self.net = keras.Sequential([\n            layers.Dense(hidden_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n\n    def call(self, x):\n        return self.net(x)\n\nclass GRASPModel(keras.Model):\n    def __init__(self, gin_config, transformer_config, projection_dim, **kwargs):\n        super(GRASPModel, self).__init__(**kwargs)\n        self.gin_encoder = GINEncoder(**gin_config)\n        self.transformer_encoder = TransformerEncoder(**transformer_config)\n        \n        self.graph_projection_head = ProjectionHead(gin_config['hidden_dim'], projection_dim)\n        self.smiles_projection_head = ProjectionHead(transformer_config['embed_dim'], projection_dim)\n\n    def call(self, inputs, training=False):\n        # Inputs are unpacked from the dataset tuple\n        node_features, edge_indices, num_nodes, token_ids, smiles_mask = inputs\n        \n        # Encoding graphs\n        graph_embeddings_raw = self.gin_encoder((node_features, edge_indices, num_nodes), training=training)\n        graph_embeddings_projected = self.graph_projection_head(graph_embeddings_raw, training=training)\n\n        # Encoding SMILES\n        smiles_embeddings_raw = self.transformer_encoder((token_ids, smiles_mask), training=training)\n        smiles_embeddings_projected = self.smiles_projection_head(smiles_embeddings_raw, training=training)\n\n        # Applying L2 normalization to projected embeddings for InfoNCE loss\n        graph_embeddings_projected = tf.linalg.normalize(graph_embeddings_projected, axis=1)[0]\n        smiles_embeddings_projected = tf.linalg.normalize(smiles_embeddings_projected, axis=1)[0]\n\n        return graph_embeddings_projected, smiles_embeddings_projected","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:50:47.211527Z","iopub.execute_input":"2025-06-22T17:50:47.211849Z","iopub.status.idle":"2025-06-22T17:50:47.243615Z","shell.execute_reply.started":"2025-06-22T17:50:47.211822Z","shell.execute_reply":"2025-06-22T17:50:47.238219Z"}},"outputs":[],"execution_count":20},{"id":"2782bc8a","cell_type":"markdown","source":"# --- Contrastive Loss (InfoNCE) ---","metadata":{}},{"id":"d09af71b","cell_type":"code","source":"class InfoNCELoss(keras.losses.Loss):\n    def __init__(self, temperature=0.07, name='info_nce_loss', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.temperature = temperature\n\n    @tf.function\n    def call(self, graph_embeddings, smiles_embeddings):\n\n        # Cosine similarity matrix (logits)\n        # S_ij = sim(g_i, s_j)\n        logits = tf.matmul(graph_embeddings, smiles_embeddings, transpose_b=True) / self.temperature\n        \n        # Creating labels: diagonal elements are positive pairs\n        batch_size = tf.shape(logits)[0]\n        labels = tf.eye(batch_size) # (batch_size, batch_size)\n\n        # Calculating cross-entropy for graph->SMILES and SMILES->graph\n        # loss_g_s: how well graph embeddings predict their corresponding SMILES\n        loss_g_s = tf.keras.losses.categorical_crossentropy(labels, logits, from_logits=True)\n        \n        # loss_s_g: how well SMILES embeddings predict their corresponding graphs\n        loss_s_g = tf.keras.losses.categorical_crossentropy(labels, tf.transpose(logits), from_logits=True)\n\n        # Total loss is the average of both directions\n        total_loss = (loss_g_s + loss_s_g) / 2\n        \n        # Reduce mean over the batch\n        return tf.reduce_mean(total_loss)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:50:51.847141Z","iopub.execute_input":"2025-06-22T17:50:51.847510Z","iopub.status.idle":"2025-06-22T17:50:51.861465Z","shell.execute_reply.started":"2025-06-22T17:50:51.847483Z","shell.execute_reply":"2025-06-22T17:50:51.855705Z"}},"outputs":[],"execution_count":21},{"id":"91840c15","cell_type":"markdown","source":"# --- Training Loop ---","metadata":{}},{"id":"131fc2e5","cell_type":"code","source":"PROJECTION_DIM = 128 # Dimension of the shared embedding space\nHIDDEN_DIM_GIN = 256 \nNUM_GIN_LAYERS = 3   \nEMBED_DIM_TRANSFORMER = 256 \nNUM_TRANSFORMER_HEADS = 8\nNUM_TRANSFORMER_LAYERS = 3\n\ngin_config = {\n    'num_layers': NUM_GIN_LAYERS,\n    'hidden_dim': HIDDEN_DIM_GIN,\n    # Atom features from featurization. This is the input_dim for the first GIN layer.\n    # It must match the output of `atom_to_feature_vector`.\n    # 'num_node_features': len(atom_to_feature_vector(Chem.Atom(6))) # Using a dummy atom to get feature count\n    'num_node_features': 5 \n}\n\ntransformer_config = {\n    'vocab_size': VOCAB_SIZE,\n    'embed_dim': EMBED_DIM_TRANSFORMER,\n    'num_heads': NUM_TRANSFORMER_HEADS,\n    'num_layers': NUM_TRANSFORMER_LAYERS,\n    'max_seq_len': MAX_SMILES_LEN\n}\n\n# Defining the training step function\n@tf.function\ndef train_step(inputs):\n    with tf.GradientTape() as tape:\n        graph_embeddings, smiles_embeddings = model(inputs, training=True)\n        loss = info_nce_loss(graph_embeddings, smiles_embeddings)\n        \n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss\n\n# Instantiating model, loss, and optimizer within the TPU strategy scope\nwith strategy.scope():\n    model = GRASPModel(gin_config, transformer_config, PROJECTION_DIM)\n    info_nce_loss = InfoNCELoss(temperature=0.07) # Adjust temperature as needed\n    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n\n    model.compile(optimizer=optimizer, loss=info_nce_loss)\n\nEPOCHS = 5 \nsteps_per_epoch = tf.data.experimental.cardinality(dataset).numpy()\n\nprint(f\"\\nStarting pre-training for {EPOCHS} epochs...\")\nprint(f\"Steps per epoch: {steps_per_epoch}\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n    total_loss = 0.0\n    num_batches = 0\n\n    for batch_inputs in dataset:\n        per_replica_losses = strategy.run(train_step, args=(batch_inputs,))\n        batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n        total_loss += batch_loss\n        num_batches += 1\n        \n        if num_batches % 10 == 0:\n            print(f\"  Batch {num_batches}/{steps_per_epoch}, Loss: {batch_loss:.4f}\", end='\\r')\n    \n    avg_loss = total_loss / num_batches\n    print(f\"Epoch {epoch + 1} finished. Average Loss: {avg_loss:.4f}\")\n\nprint(\"\\nPre-training complete!\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:54:49.497368Z","iopub.execute_input":"2025-06-22T17:54:49.497762Z","iopub.status.idle":"2025-06-22T17:54:49.705034Z","shell.execute_reply.started":"2025-06-22T17:54:49.497733Z","shell.execute_reply":"2025-06-22T17:54:49.700996Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Instantiating model, loss, and optimizer within the TPU strategy scope\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m---> 38\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mGRASPModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgin_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROJECTION_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     info_nce_loss \u001b[38;5;241m=\u001b[39m InfoNCELoss(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.07\u001b[39m) \u001b[38;5;66;03m# Adjust temperature as needed\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n","Cell \u001b[0;32mIn[20], line 158\u001b[0m, in \u001b[0;36mGRASPModel.__init__\u001b[0;34m(self, gin_config, transformer_config, projection_dim, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, gin_config, transformer_config, projection_dim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28msuper\u001b[39m(GRASPModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgin_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mGINEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgin_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder \u001b[38;5;241m=\u001b[39m TransformerEncoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtransformer_config)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_projection_head \u001b[38;5;241m=\u001b[39m ProjectionHead(gin_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m], projection_dim)\n","Cell \u001b[0;32mIn[20], line 43\u001b[0m, in \u001b[0;36mGINEncoder.__init__\u001b[0;34m(self, num_layers, hidden_dim, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_layers, hidden_dim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGINEncoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgin_layers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers):\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/models/model.py:158\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     functional\u001b[38;5;241m.\u001b[39mFunctional\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[43mLayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/layers/layer.py:289\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to GINEncoder: {'num_node_features': 5}"],"ename":"ValueError","evalue":"Unrecognized keyword arguments passed to GINEncoder: {'num_node_features': 5}","output_type":"error"}],"execution_count":23},{"id":"fb53c3b9","cell_type":"markdown","source":"# --- Saving the model ---","metadata":{}},{"id":"dd015d93","cell_type":"code","source":"# To save just the encoders:\n# tf.saved_model.save(model.gin_encoder, 'gin_encoder_pretrained')\n# tf.saved_model.save(model.transformer_encoder, 'transformer_encoder_pretrained')\n# print(\"Encoders saved.\")\n\n\nmodel.save('grasp_pretrained_model')\nprint(\"Model saved to 'grasp_pretrained_model' directory.\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.993678Z","iopub.status.idle":"2025-06-22T17:45:24.996239Z","shell.execute_reply.started":"2025-06-22T17:45:24.994622Z","shell.execute_reply":"2025-06-22T17:45:24.994637Z"}},"outputs":[],"execution_count":null}]}