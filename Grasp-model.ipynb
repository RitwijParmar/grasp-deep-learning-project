{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12249061,"sourceType":"datasetVersion","datasetId":7718046}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"37bd6b3a-cbe9-4166-ad2a-a4399cfd9de1","cell_type":"code","source":"!pip install rdkit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:01:19.434541Z","iopub.execute_input":"2025-06-22T20:01:19.434808Z","iopub.status.idle":"2025-06-22T20:01:27.811474Z","shell.execute_reply.started":"2025-06-22T20:01:19.434782Z","shell.execute_reply":"2025-06-22T20:01:27.806770Z"}},"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2025.3.3-cp310-cp310-manylinux_2_28_x86_64.whl (34.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (2.0.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (11.2.1)\nInstalling collected packages: rdkit\nSuccessfully installed rdkit-2025.3.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"id":"0f6aad75-9f70-4dbf-8a5d-35350d245adb","cell_type":"code","source":"# Importing Libraries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:01:27.812927Z","iopub.execute_input":"2025-06-22T20:01:27.813172Z","iopub.status.idle":"2025-06-22T20:01:27.822002Z","shell.execute_reply.started":"2025-06-22T20:01:27.813147Z","shell.execute_reply":"2025-06-22T20:01:27.816821Z"}},"outputs":[],"execution_count":2},{"id":"b81e89b2","cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom rdkit import Chem","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:01:27.823651Z","iopub.execute_input":"2025-06-22T20:01:27.823834Z","iopub.status.idle":"2025-06-22T20:01:51.027082Z","shell.execute_reply.started":"2025-06-22T20:01:27.823815Z","shell.execute_reply":"2025-06-22T20:01:51.022711Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1750622494.882225      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"}],"execution_count":3},{"id":"bc26ddeb","cell_type":"markdown","source":"# init TPU (as we are using the Kaggle TPU 4 for faster processing)","metadata":{}},{"id":"b0a921b5","cell_type":"code","source":"\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n    print('Not running on TPU, defaulting to GPU/CPU.')\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # Default to GPU or CPU strategy\n\nprint(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:01:51.029546Z","iopub.execute_input":"2025-06-22T20:01:51.031463Z","iopub.status.idle":"2025-06-22T20:01:51.042635Z","shell.execute_reply.started":"2025-06-22T20:01:51.031432Z","shell.execute_reply":"2025-06-22T20:01:51.038152Z"}},"outputs":[{"name":"stdout","text":"Not running on TPU, defaulting to GPU/CPU.\nNumber of accelerators: 1\n","output_type":"stream"}],"execution_count":4},{"id":"ced008e2","cell_type":"markdown","source":"# Data Loading and preprocesing","metadata":{}},{"id":"9bb21682","cell_type":"code","source":"SMILES_FILE_PATH = '/kaggle/input/pubchem-smiles-for-pretraining/pubchem_smiles_for_pretraining.txt'\n\nmax_nodes_found = 0\nnum_lines_to_check = 100000 \n\nwith open(SMILES_FILE_PATH, 'r') as f:\n    for i, line in enumerate(f):\n        if i >= num_lines_to_check:\n            break\n        smiles = line.strip()\n        mol = Chem.MolFromSmiles(smiles)\n        if mol:\n            num_nodes = mol.GetNumAtoms()\n            if num_nodes > max_nodes_found:\n                max_nodes_found = num_nodes\nprint(f\"Maximum nodes found in the first {num_lines_to_check} molecules: {max_nodes_found}\")\n\ndef load_smiles_data(file_path, num_samples=None):\n    smiles_list = []\n    with open(file_path, 'r') as f:\n        for i, line in enumerate(f):\n            if num_samples and i >= num_samples:\n                break\n            smiles_list.append(line.strip())\n    print(f\"Loaded {len(smiles_list)} SMILES strings.\")\n    return smiles_list\n\n\n# For testing we will use 50,000; 100,000 for quick tests basically.\nall_smiles = load_smiles_data(SMILES_FILE_PATH, num_samples=100000) \n\n# We are Defining the featurization function for the dataset map operation\ndef featurize_smiles_and_graph(smiles_string):\n    token_ids = tokenize_smiles(smiles_string.numpy().decode('utf-8'), char_to_idx, MAX_SMILES_LEN)\n    mask = create_smiles_mask(token_ids, char_to_idx['<pad>'])\n\n    node_features, edge_indices, num_nodes, num_edges = smiles_to_tf_graph(smiles_string.numpy().decode('utf-8'))\n\n    # Handling the cases where graph conversion fails (e.g., invalid smiles)\n    if node_features is None:\n        dummy_edge_indices = tf.zeros((0, 2), dtype=tf.int32)\n        dummy_num_nodes = tf.constant(0, dtype=tf.int32)\n        dummy_num_edges = tf.constant(0, dtype=tf.int32) \n        return dummy_node_features, dummy_edge_indices, dummy_num_nodes, dummy_num_edges, token_ids, mask \n    \n    # We will ensure node_features has consistent shape by padding if necessary for batching\n    # It assumes a maximum number of nodes in any graph.\n    padded_node_features = tf.pad(node_features, [[0, MAX_NODES - num_nodes], [0, 0]])\n    \n    return (tf.constant(padded_node_features, dtype=tf.float32),\n            tf.constant(edge_indices, dtype=tf.int32),\n            tf.constant(num_nodes, dtype=tf.int32),\n            tf.constant(num_edges, dtype=tf.int32),\n            tf.constant(token_ids, dtype=tf.int32),\n            tf.constant(mask, dtype=tf.bool))\n\ndataset = tf.data.Dataset.from_tensor_slices(all_smiles)\n\n# Mapping the featurization function by using tf.py_function for non-TF operations (RDKit)\ndataset = dataset.map(lambda x: tf.py_function(\n    featurize_smiles_and_graph,\n    inp=[x],\n    Tout=(tf.float32, tf.int32, tf.int32, tf.int32, tf.int32, tf.bool) \n), num_parallel_calls=tf.data.AUTOTUNE)\n\n# Filtering out the failed conversions\ndataset = dataset.filter(lambda node_feat, edge_idx, num_nodes, num_edges, token_ids, mask: num_nodes > 0)\n\nBATCH_SIZE_PER_REPLICA = 64 \nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:01:51.044702Z","iopub.execute_input":"2025-06-22T20:01:51.044922Z","iopub.status.idle":"2025-06-22T20:02:08.943067Z","shell.execute_reply.started":"2025-06-22T20:01:51.044902Z","shell.execute_reply":"2025-06-22T20:02:08.938139Z"}},"outputs":[{"name":"stderr","text":"[20:01:51] WARNING: not removing hydrogen atom without neighbors\n[20:01:53] WARNING: not removing hydrogen atom without neighbors\n[20:01:54] WARNING: not removing hydrogen atom without neighbors\n[20:01:54] WARNING: not removing hydrogen atom without neighbors\n[20:01:54] WARNING: not removing hydrogen atom without neighbors\n[20:01:54] WARNING: not removing hydrogen atom without neighbors\n[20:01:54] WARNING: not removing hydrogen atom without neighbors\n[20:01:54] WARNING: not removing hydrogen atom without neighbors\n[20:01:54] WARNING: not removing hydrogen atom without neighbors\n[20:01:58] WARNING: not removing hydrogen atom without neighbors\n[20:01:58] WARNING: not removing hydrogen atom without neighbors\n[20:01:58] WARNING: not removing hydrogen atom without neighbors\n[20:02:00] WARNING: not removing hydrogen atom without neighbors\n[20:02:00] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:01] WARNING: not removing hydrogen atom without neighbors\n[20:02:02] WARNING: not removing hydrogen atom without neighbors\n[20:02:02] WARNING: not removing hydrogen atom without neighbors\n[20:02:02] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:03] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n[20:02:04] WARNING: not removing hydrogen atom without neighbors\n","output_type":"stream"},{"name":"stdout","text":"Maximum nodes found in the first 100000 molecules: 419\nLoaded 100000 SMILES strings.\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750622528.830574      10 service.cc:148] XLA service 0x592af79b8810 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750622528.830615      10 service.cc:156]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1750622528.830619      10 service.cc:156]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1750622528.830622      10 service.cc:156]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1750622528.830625      10 service.cc:156]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1750622528.830627      10 service.cc:156]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1750622528.830629      10 service.cc:156]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1750622528.830632      10 service.cc:156]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1750622528.830637      10 service.cc:156]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"}],"execution_count":5},{"id":"dfb6f6e4","cell_type":"markdown","source":"# --- Creating tf.data.Dataset for TPU ---","metadata":{}},{"id":"bda19fa9","cell_type":"code","source":"# --- SMILES Tokenization ---\n# A simple character-level tokenizer for demonstration.\ndef build_smiles_vocab(smiles_list, max_vocab_size=None):\n    all_chars = set()\n    for smiles in smiles_list:\n        for char in smiles:\n            all_chars.add(char)\n    vocab = sorted(list(all_chars))\n    # Adding special tokens\n    vocab = ['<pad>', '<unk>', '<cls>', '<eos>'] + vocab\n    if max_vocab_size:\n        vocab = vocab[:max_vocab_size]\n    char_to_idx = {char: i for i, char in enumerate(vocab)}\n    idx_to_char = {i: char for i, char in enumerate(vocab)}\n    print(f\"Built vocabulary of size: {len(vocab)}\")\n    return vocab, char_to_idx, idx_to_char\n\nvocab, char_to_idx, idx_to_char = build_smiles_vocab(all_smiles)\nVOCAB_SIZE = len(vocab)\nMAX_SMILES_LEN = 256 # Max sequence length for Transformer.\nMAX_NODES = max_nodes_found # Maximum number of nodes in any graph in a batch.\n\ndef tokenize_smiles(smiles, char_to_idx, max_len):\n    \"\"\"Here we basically plan to convert a SMILES string to a sequence of token IDs.\"\"\"\n    tokens = list(smiles)\n    indexed_tokens = [char_to_idx.get(char, char_to_idx['<unk>']) for char in tokens]\n    \n    # Pad or truncate\n    if len(indexed_tokens) < max_len:\n        padded_tokens = indexed_tokens + [char_to_idx['<pad>']] * (max_len - len(indexed_tokens))\n    else:\n        padded_tokens = indexed_tokens[:max_len]\n    return np.array(padded_tokens, dtype=np.int32)\n\ndef create_smiles_mask(token_ids, pad_token_id):\n    \"\"\"This will create a boolean mask for padded tokens.\"\"\"\n    return tf.cast(token_ids == pad_token_id, tf.bool)\n\n\n# --- SMILES to TensorFlow Graph Conversion ---\n# This is the critical part, transforming SMILES to a graph representation which will be usable by a TensorFlow GNN, specifically sparse tensors for efficiency.\n\n# Defining the atom and bond features\n# These are just example indices for features, along the way we will design specific one-hot encodings or numerical features based on chemical intuition.\nATOM_FEATURES_LIST = [\n    6, 7, 8, 9, 15, 16, 17, 35, 53, # Atomic number (C, N, O, F, P, S, Cl, Br, I)\n    1, 2, 3, 4, # Degree (number of bonds)\n    0, 1, 2, 3, 4, # Hybridization (SP, SP2, SP3, SP3D, SP3D2 as ints)\n    0, 1, # Is aromatic\n    -1, 0, 1, 2, 3, 4 # Formal charge\n]\nNUM_ATOM_FEATURES = len(ATOM_FEATURES_LIST) # we are gonna make it the output dim of our featurizer\n\nBOND_FEATURES_LIST = [\n    Chem.BondType.SINGLE, Chem.BondType.DOUBLE, Chem.BondType.TRIPLE, Chem.BondType.AROMATIC, # Bond types\n    0, 1 # Is conjugated\n]\nNUM_BOND_FEATURES = len(BOND_FEATURES_LIST) # we will also make this the output dim of our featurizer\n\npadded_shapes = (\n    tf.TensorShape([MAX_NODES, NUM_ATOM_FEATURES]), # node_features\n    tf.TensorShape([None, 2]), # edge_indices (variable length per graph in batch)\n    tf.TensorShape([]),        # num_nodes (scalar per graph)\n    tf.TensorShape([]),        # num_edges (scalar per graph) \n    tf.TensorShape([MAX_SMILES_LEN]), # token_ids\n    tf.TensorShape([MAX_SMILES_LEN])  # mask\n)\npadding_values = (\n    tf.constant(0.0, dtype=tf.float32), # node_features padding\n    tf.constant(0, dtype=tf.int32),     # edge_indices padding\n    tf.constant(0, dtype=tf.int32),     # num_nodes padding\n    tf.constant(0, dtype=tf.int32),     # num_edges padding \n    tf.constant(char_to_idx['<pad>'], dtype=tf.int32), # token_ids padding\n    tf.constant(True, dtype=tf.bool)    # mask padding\n)\n\ndataset = dataset.cache() # We are Caching data after featurization for faster epochs\ndataset = dataset.shuffle(buffer_size=10000) \ndataset = dataset.padded_batch(GLOBAL_BATCH_SIZE, padded_shapes=padded_shapes, padding_values=padding_values, drop_remainder=True)\ndataset = dataset.prefetch(tf.data.AUTOTUNE)\n\ndef atom_to_feature_vector(atom):\n    \"\"\"This will convert an RDKit atom to a feature vector.\"\"\"\n    features = []\n    # Atomic number (one-hot or direct embedding if using learned features)\n    features.append(atom.GetAtomicNum())\n    features.append(atom.GetDegree())\n    features.append(int(atom.GetHybridization())) # Convert enum to int\n    features.append(int(atom.GetIsAromatic()))\n    features.append(atom.GetFormalCharge())\n    return np.array(features, dtype=np.float32)\n\ndef bond_to_feature_vector(bond):\n    \"\"\"converting an RDKit bond to a feature vector.\"\"\"\n    features = []\n    features.append(int(bond.GetBondType()))\n    features.append(int(bond.GetIsConjugated()))\n    return np.array(features, dtype=np.float32)\n\ndef smiles_to_tf_graph(smiles_string):\n    \"\"\"\n    Converts a SMILES string to TensorFlow graph components:\n    node_features, edge_indices, num_nodes, and num_edges.\n    \"\"\"\n    mol = Chem.MolFromSmiles(smiles_string)\n    if mol is None:\n        # Return Nones for graph data when RDKit fails to parse SMILES\n        # Ensuring all 4 return values are present\n        return None, None, None, None \n\n    # Getting node features\n    node_features = [atom_to_feature_vector(atom) for atom in mol.GetAtoms()]\n    if not node_features: # Handle empty molecules after atom featurization (should be rare)\n        # Ensuring all 4 return values are present\n        return None, None, None, None \n    node_features = np.array(node_features, dtype=np.float32)\n    num_nodes = len(node_features)\n\n    # Get edge indices (adjacency list format)\n    edge_indices = []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_indices.append([i, j])\n        edge_indices.append([j, i])  # Adding the reverse edge for undirected graph\n\n    # --- CRITICAL FIXES START HERE ---\n    # Use explicit length check for `edge_indices` (which is a Python list at this point)\n    if len(edge_indices) == 0: \n        # Handle single atom molecules or molecules with no bonds\n        if num_nodes == 1:\n            edge_indices_final = np.array([[0, 0]], dtype=np.int32) # Add a self-loop as a NumPy array\n            num_edges_final = 1 # Update num_edges for the self-loop\n        else:\n            # For molecules with >1 node but no bonds (e.g., [C].[C]),\n            # or where parsing failed to produce bonds.\n            edge_indices_final = tf.zeros((0, 2), dtype=tf.int32) # Return empty TF tensor\n            num_edges_final = 0 # No edges\n        \n        # All return paths now explicitly return all 4 values\n        return node_features, edge_indices_final, num_nodes, num_edges_final\n    \n    # If `edge_indices` was not empty initially, convert it to numpy array\n    edge_indices_final = np.array(edge_indices, dtype=np.int32)\n    \n    # The final `num_edges` should be the length of the *array* of edges being returned.\n    num_edges_final = len(edge_indices_final) # Robustly get the count from the final edge array\n\n    return node_features, edge_indices_final, num_nodes, num_edges_final","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:02:08.944760Z","iopub.execute_input":"2025-06-22T20:02:08.944979Z","iopub.status.idle":"2025-06-22T20:02:09.191608Z","shell.execute_reply.started":"2025-06-22T20:02:08.944958Z","shell.execute_reply":"2025-06-22T20:02:09.187151Z"}},"outputs":[{"name":"stdout","text":"Built vocabulary of size: 71\n","output_type":"stream"}],"execution_count":6},{"id":"ce3cc0f8","cell_type":"markdown","source":"# --- Model Architecture (TensorFlow/Keras) ---","metadata":{}},{"id":"63e7bcbe","cell_type":"code","source":"# GIN Layer (as a Custom Keras Layer) we are doing it as this implements the core GIN aggregation as a Keras layer suitable for sparse tensors and TPU\nclass GINLayer(layers.Layer):\n    def __init__(self, output_dim, activation=None, **kwargs):\n        super(GINLayer, self).__init__(**kwargs)\n        self.output_dim = output_dim\n        self.mlp = keras.Sequential([\n            layers.Dense(output_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n        self.epsilon = self.add_weight(name='epsilon', shape=(),\n                                       initializer=keras.initializers.Constant(0.0),\n                                       trainable=True)\n        self.activation = keras.activations.get(activation)\n\n    def call(self, inputs):\n        node_features, edge_indices_batch, num_nodes_batch = inputs\n        \n        edge_values = tf.ones(tf.shape(edge_indices_batch)[0], dtype=tf.float32)\n        \n        total_nodes_in_batch = tf.shape(node_features)[0]\n        adj_shape = tf.cast([total_nodes_in_batch, total_nodes_in_batch], dtype=tf.int64)\n\n        adj_sparse = tf.sparse.SparseTensor(indices=tf.cast(edge_indices_batch, tf.int64),\n                                            values=edge_values,\n                                            dense_shape=adj_shape)\n        \n        # Sum of neighbor features: (A * H)\n        neighbor_sum = tf.sparse.sparse_dense_matmul(adj_sparse, node_features)\n\n        # GIN update: MLP((1 + epsilon) * H + Sum(Neighbors))\n        combined_features = (1 + self.epsilon) * node_features + neighbor_sum\n        output = self.mlp(combined_features)\n\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0][0], self.output_dim # (batch_size * max_nodes_per_graph, output_dim)\n\nclass GINEncoder(keras.Model):\n    def __init__(self, num_layers, hidden_dim, num_node_features, **kwargs): \n        super(GINEncoder, self).__init__(**kwargs)\n        self.hidden_dim = hidden_dim \n        \n        self.initial_mlp = keras.Sequential([\n            layers.Dense(hidden_dim, activation='relu'),\n            layers.Dense(hidden_dim) \n        ])\n        \n        self.gin_layers = []\n        self.bns = [] # Initialize the list for Batch Normalization layers\n        \n        # Loop to create GIN layers AND corresponding Batch Normalization layers\n        # Each GINLayer will be followed by a BatchNorm.\n        for i in range(num_layers): \n            self.gin_layers.append(GINLayer(hidden_dim, activation='relu' if i < num_layers - 1 else None))\n            self.bns.append(layers.BatchNormalization())\n    \n    def call(self, inputs):\n        node_features, edge_indices, num_nodes = inputs\n\n        x = self.initial_mlp(node_features) # Applying initial transformation\n        \n        # Correctly iterate through corresponding GIN and BatchNorm layers\n        for i in range(len(self.gin_layers)): \n            x = self.gin_layers[i]((x, edge_indices, num_nodes)) # Pass inputs to GINLayer\n            x = self.bns[i](x) # Apply BatchNorm AFTER the GINLayer output\n        \n        batch_size = tf.shape(node_features)[0] // MAX_NODES\n        \n        # Reshaping to (batch_size, MAX_NODES, hidden_dim)\n        # Use the hidden_dim as the last dimension, it's consistent for GIN layers.\n        x_reshaped = tf.reshape(x, (batch_size, MAX_NODES, self.hidden_dim)) \n        \n        # Creating a mask for valid nodes in each graph\n        sequence_mask = tf.sequence_mask(num_nodes, maxlen=MAX_NODES, dtype=tf.float32) \n        sequence_mask = tf.expand_dims(sequence_mask, axis=-1) \n        \n        # Applying mask and sum\n        masked_x = x_reshaped * sequence_mask\n        graph_embedding = tf.reduce_sum(masked_x, axis=1) # Sum pooling\n        \n        return graph_embedding\n\nclass TransformerEncoder(keras.Model):\n    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, max_seq_len, dropout_rate=0.1, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.token_embedding = layers.Embedding(vocab_size, embed_dim)\n        self.positional_embedding = self.add_weight(\n            name=\"pos_embed\",\n            shape=(1, max_seq_len, embed_dim),\n            initializer=\"random_normal\",\n            trainable=True\n        )\n\n        self.encoder_layers = []\n        for _ in range(num_layers):\n            self.encoder_layers.append([\n                layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout_rate),\n                layers.LayerNormalization(epsilon=1e-6),\n                layers.Dense(embed_dim * 4, activation=\"relu\"),\n                layers.Dense(embed_dim),\n                layers.LayerNormalization(epsilon=1e-6),\n            ])\n        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, inputs, training=False, mask=None): # 'mask' parameter is actually `padding_mask` from GRASPModel\n        token_ids, padding_mask_bool = inputs # Renamed to padding_mask_bool for clarity\n        \n        x = self.token_embedding(token_ids)\n        x = x + self.positional_embedding[:, :tf.shape(x)[1], :]\n\n        # Create an additive attention mask from the boolean padding_mask\n        # MultiHeadAttention expects a mask that is added to the attention scores (logits).\n        \n        attention_mask_additive = tf.cast(padding_mask_bool, dtype=tf.float32) * -1e9\n        \n        # Simplest form of additive mask for Keras MHA: (batch_size, 1, key_sequence_length)\n        # This will be broadcast across query dimension and heads.\n        attention_mask_additive = tf.expand_dims(attention_mask_additive, axis=1) # (batch_size, 1, MAX_SMILES_LEN)\n        \n        \n        for i, (attention, norm1, ff_dense1, ff_dense2, norm2) in enumerate(self.encoder_layers):\n            # Attention block\n            # Pass the prepared additive mask\n            attn_output = attention(x, x, attention_mask=attention_mask_additive, training=training)\n            x = norm1(x + attn_output) # Add & Norm\n\n            # Feed-forward block\n            ff_output = ff_dense2(ff_dense1(x))\n            x = norm2(x + ff_output) # Add & Norm\n        \n        # Global pooling: mask out padded tokens before mean pooling\n\n        expanded_padding_mask = tf.cast(tf.expand_dims(padding_mask_bool, axis=-1), dtype=x.dtype)\n        \n        # Invert the mask logic: 1.0 for non-padded, 0.0 for padded\n        non_padded_mask = 1.0 - expanded_padding_mask\n        \n        # Apply mask: so we will set padded embeddings to 0\n        x_masked = x * non_padded_mask\n        \n        # Sum along sequence dimension\n        sum_embeddings = tf.reduce_sum(x_masked, axis=1)\n        \n        # Counting non-padded elements per sequence\n        non_padded_len = tf.reduce_sum(non_padded_mask, axis=1)\n        \n        # Mean pooling (also avoiding division by zero for fully padded sequences)\n        smiles_embedding = sum_embeddings / (non_padded_len + 1e-9) # Adding epsilon to avoid div by zero\n        \n        return self.final_norm(smiles_embedding)\n\n\nclass ProjectionHead(keras.Model):\n    def __init__(self, input_dim, output_dim, hidden_dim=256, **kwargs):\n        super(ProjectionHead, self).__init__(**kwargs)\n        self.net = keras.Sequential([\n            layers.Dense(hidden_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n\n    def call(self, x):\n        return self.net(x)\n\nclass GRASPModel(keras.Model):\n    def __init__(self, gin_config, transformer_config, projection_dim, **kwargs):\n        super(GRASPModel, self).__init__(**kwargs)\n        self.gin_encoder = GINEncoder(**gin_config)\n        self.transformer_encoder = TransformerEncoder(**transformer_config)\n        \n        self.graph_projection_head = ProjectionHead(gin_config['hidden_dim'], projection_dim)\n        self.smiles_projection_head = ProjectionHead(transformer_config['embed_dim'], projection_dim)\n    \n    def call(self, inputs, training=False):\n        node_features_padded, edge_indices_padded, num_nodes, num_edges, token_ids, smiles_mask = inputs\n        \n        node_features_flat = tf.reshape(node_features_padded, (-1, tf.shape(node_features_padded)[2]))\n        \n        batch_size = tf.shape(node_features_padded)[0] \n        \n        # --- Handling Edge Indices for GINLayer ---\n        # Creating a mask to identify valid edges (non-padded ones)\n        edge_mask = tf.sequence_mask(num_edges, maxlen=tf.shape(edge_indices_padded)[1], dtype=tf.bool)\n         \n        # Filtering out padded edges, This will bascially flatten the valid edges across the entire batch\n        valid_edge_indices = tf.boolean_mask(edge_indices_padded, edge_mask)\n        \n        # Creating global node offsets for each graph in the batch\n        # This transforms local node IDs (0 to MAX_NODES-1) into global IDs across the flattened node list\n        node_offsets_for_edges = tf.range(batch_size) * MAX_NODES \n        # Expanding and tiling this offset to apply to each edge\n        node_offsets_for_edges = tf.expand_dims(node_offsets_for_edges, axis=1) \n        node_offsets_for_edges_expanded = tf.boolean_mask(tf.tile(node_offsets_for_edges, [1, tf.shape(edge_indices_padded)[1]]), edge_mask)\n        node_offsets_for_edges_expanded = tf.expand_dims(node_offsets_for_edges_expanded, axis=-1) \n        \n        # Applying offsets to get global edge indices\n        global_edge_indices_filtered = valid_edge_indices + tf.cast(node_offsets_for_edges_expanded, dtype=tf.int32)\n        \n        # Encoding graphs\n        graph_embeddings_raw = self.gin_encoder((node_features_flat, global_edge_indices_filtered, num_nodes), training=training)\n        graph_embeddings_projected = self.graph_projection_head(graph_embeddings_raw, training=training)\n        \n        # Encode SMILES\n        smiles_embeddings_raw = self.transformer_encoder((token_ids, smiles_mask), training=training)\n        smiles_embeddings_projected = self.smiles_projection_head(smiles_embeddings_raw, training=training)\n        \n        # Apply L2 normalization to projected embeddings for InfoNCE loss\n        graph_embeddings_projected = tf.linalg.normalize(graph_embeddings_projected, axis=1)[0]\n        smiles_embeddings_projected = tf.linalg.normalize(smiles_embeddings_projected, axis=1)[0]\n        \n        return graph_embeddings_projected, smiles_embeddings_projected","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:15:44.119594Z","iopub.execute_input":"2025-06-22T20:15:44.119956Z","iopub.status.idle":"2025-06-22T20:15:44.154329Z","shell.execute_reply.started":"2025-06-22T20:15:44.119927Z","shell.execute_reply":"2025-06-22T20:15:44.149766Z"}},"outputs":[],"execution_count":19},{"id":"2782bc8a","cell_type":"markdown","source":"# --- Contrastive Loss (InfoNCE) ---","metadata":{}},{"id":"d09af71b","cell_type":"code","source":"class InfoNCELoss(keras.losses.Loss):\n    def __init__(self, temperature=0.07, name='info_nce_loss', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.temperature = temperature\n\n    @tf.function\n    def call(self, graph_embeddings, smiles_embeddings):\n\n        # Cosine similarity matrix (logits)\n        # S_ij = sim(g_i, s_j)\n        logits = tf.matmul(graph_embeddings, smiles_embeddings, transpose_b=True) / self.temperature\n        \n        # Creating labels: diagonal elements are positive pairs\n        batch_size = tf.shape(logits)[0]\n        labels = tf.eye(batch_size) # (batch_size, batch_size)\n\n        # Calculating cross-entropy for graph->SMILES and SMILES->graph\n        # loss_g_s: how well graph embeddings predict their corresponding SMILES\n        loss_g_s = tf.keras.losses.categorical_crossentropy(labels, logits, from_logits=True)\n        \n        # loss_s_g: how well SMILES embeddings predict their corresponding graphs\n        loss_s_g = tf.keras.losses.categorical_crossentropy(labels, tf.transpose(logits), from_logits=True)\n\n        # Total loss is the average of both directions\n        total_loss = (loss_g_s + loss_s_g) / 2\n        \n        # Reduce mean over the batch\n        return tf.reduce_mean(total_loss)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:15:46.770474Z","iopub.execute_input":"2025-06-22T20:15:46.770807Z","iopub.status.idle":"2025-06-22T20:15:46.785846Z","shell.execute_reply.started":"2025-06-22T20:15:46.770779Z","shell.execute_reply":"2025-06-22T20:15:46.779727Z"}},"outputs":[],"execution_count":20},{"id":"91840c15","cell_type":"markdown","source":"# --- Training Loop ---","metadata":{}},{"id":"131fc2e5","cell_type":"code","source":"PROJECTION_DIM = 128 # Dimension of the shared embedding space\nHIDDEN_DIM_GIN = 256 \nNUM_GIN_LAYERS = 3   \nEMBED_DIM_TRANSFORMER = 256 \nNUM_TRANSFORMER_HEADS = 8\nNUM_TRANSFORMER_LAYERS = 3\n\ngin_config = {\n    'num_layers': NUM_GIN_LAYERS,\n    'hidden_dim': HIDDEN_DIM_GIN,\n    # Atom features from featurization. This is the input_dim for the first GIN layer.\n    # It must match the output of `atom_to_feature_vector`.\n    # 'num_node_features': len(atom_to_feature_vector(Chem.Atom(6))) # Using a dummy atom to get feature count\n    'num_node_features': 5 \n}\n\ntransformer_config = {\n    'vocab_size': VOCAB_SIZE,\n    'embed_dim': EMBED_DIM_TRANSFORMER,\n    'num_heads': NUM_TRANSFORMER_HEADS,\n    'num_layers': NUM_TRANSFORMER_LAYERS,\n    'max_seq_len': MAX_SMILES_LEN\n}\n\n# Defining the training step function\n@tf.function\ndef train_step(inputs):\n    with tf.GradientTape() as tape:\n        graph_embeddings, smiles_embeddings = model(inputs, training=True)\n        loss = info_nce_loss(graph_embeddings, smiles_embeddings)\n        \n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss\n\n# Instantiating model, loss, and optimizer within the TPU strategy scope\nwith strategy.scope():\n    model = GRASPModel(gin_config, transformer_config, PROJECTION_DIM)\n    info_nce_loss = InfoNCELoss(temperature=0.07) # Adjust temperature as needed\n    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n\n    model.compile(optimizer=optimizer, loss=info_nce_loss)\n\nEPOCHS = 5 \nsteps_per_epoch = tf.data.experimental.cardinality(dataset).numpy()\n\nprint(f\"\\nStarting pre-training for {EPOCHS} epochs...\")\nprint(f\"Steps per epoch: {steps_per_epoch}\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n    total_loss = 0.0\n    num_batches = 0\n\n    for batch_inputs in dataset:\n        per_replica_losses = strategy.run(train_step, args=(batch_inputs,))\n        batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n        total_loss += batch_loss\n        num_batches += 1\n        \n        if num_batches % 10 == 0:\n            print(f\"  Batch {num_batches}/{steps_per_epoch}, Loss: {batch_loss:.4f}\", end='\\r')\n    \n    avg_loss = total_loss / num_batches\n    print(f\"Epoch {epoch + 1} finished. Average Loss: {avg_loss:.4f}\")\n\nprint(\"\\nPre-training complete!\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T20:15:47.601650Z","iopub.execute_input":"2025-06-22T20:15:47.601880Z"}},"outputs":[{"name":"stdout","text":"\nStarting pre-training for 5 epochs...\nSteps per epoch: -2\n\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"[20:15:49] WARNING: not removing hydrogen atom without neighbors\n","output_type":"stream"},{"name":"stdout","text":"WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x7beb3c0ed480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 7 calls to <function train_step at 0x7beb3c0ed480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n  Batch 40/-2, Loss: 2.3677\r","output_type":"stream"}],"execution_count":null},{"id":"fb53c3b9","cell_type":"markdown","source":"# --- Saving the model ---","metadata":{}},{"id":"dd015d93","cell_type":"code","source":"# To save just the encoders:\n# tf.saved_model.save(model.gin_encoder, 'gin_encoder_pretrained')\n# tf.saved_model.save(model.transformer_encoder, 'transformer_encoder_pretrained')\n# print(\"Encoders saved.\")\n\n\nmodel.save('grasp_pretrained_model')\nprint(\"Model saved to 'grasp_pretrained_model' directory.\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null},{"id":"f02d68ab-1a08-4fd2-ac59-265c98a6ca8e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}