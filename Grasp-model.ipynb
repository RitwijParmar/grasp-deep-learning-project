{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12249061,"sourceType":"datasetVersion","datasetId":7718046}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"37bd6b3a-cbe9-4166-ad2a-a4399cfd9de1","cell_type":"code","source":"!pip install rdkit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:21.269280Z","iopub.execute_input":"2025-06-22T17:45:21.269623Z","iopub.status.idle":"2025-06-22T17:45:24.741819Z","shell.execute_reply.started":"2025-06-22T17:45:21.269589Z","shell.execute_reply":"2025-06-22T17:45:24.736839Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rdkit in /usr/local/lib/python3.10/site-packages (2025.3.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (2.0.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from rdkit) (11.2.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":10},{"id":"0f6aad75-9f70-4dbf-8a5d-35350d245adb","cell_type":"code","source":"# Importing Libraries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.743095Z","iopub.execute_input":"2025-06-22T17:45:24.743360Z","iopub.status.idle":"2025-06-22T17:45:24.752842Z","shell.execute_reply.started":"2025-06-22T17:45:24.743328Z","shell.execute_reply":"2025-06-22T17:45:24.748510Z"}},"outputs":[],"execution_count":11},{"id":"b81e89b2","cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom rdkit import Chem","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.754584Z","iopub.execute_input":"2025-06-22T17:45:24.754931Z","iopub.status.idle":"2025-06-22T17:45:24.768448Z","shell.execute_reply.started":"2025-06-22T17:45:24.754910Z","shell.execute_reply":"2025-06-22T17:45:24.762087Z"}},"outputs":[],"execution_count":12},{"id":"bc26ddeb","cell_type":"markdown","source":"# init TPU (as we are using the Kaggle TPU 4 for faster processing)","metadata":{}},{"id":"b0a921b5","cell_type":"code","source":"\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n    print('Not running on TPU, defaulting to GPU/CPU.')\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # Default to GPU or CPU strategy\n\nprint(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.770456Z","iopub.execute_input":"2025-06-22T17:45:24.770683Z","iopub.status.idle":"2025-06-22T17:45:24.780979Z","shell.execute_reply.started":"2025-06-22T17:45:24.770661Z","shell.execute_reply":"2025-06-22T17:45:24.776806Z"}},"outputs":[{"name":"stdout","text":"Not running on TPU, defaulting to GPU/CPU.\nNumber of accelerators: 1\n","output_type":"stream"}],"execution_count":13},{"id":"ced008e2","cell_type":"markdown","source":"# Data Loading and preprocesing","metadata":{}},{"id":"bda19fa9","cell_type":"code","source":"SMILES_FILE_PATH = '/kaggle/input/pubchem-smiles-for-pretraining/pubchem_smiles_for_pretraining.txt'\n\nmax_nodes_found = 0\nnum_lines_to_check = 100000 \n\nwith open(SMILES_FILE_PATH, 'r') as f:\n    for i, line in enumerate(f):\n        if i >= num_lines_to_check:\n            break\n        smiles = line.strip()\n        mol = Chem.MolFromSmiles(smiles)\n        if mol:\n            num_nodes = mol.GetNumAtoms()\n            if num_nodes > max_nodes_found:\n                max_nodes_found = num_nodes\nprint(f\"Maximum nodes found in the first {num_lines_to_check} molecules: {max_nodes_found}\")\n\ndef load_smiles_data(file_path, num_samples=None):\n    smiles_list = []\n    with open(file_path, 'r') as f:\n        for i, line in enumerate(f):\n            if num_samples and i >= num_samples:\n                break\n            smiles_list.append(line.strip())\n    print(f\"Loaded {len(smiles_list)} SMILES strings.\")\n    return smiles_list\n\n\n# For testing we will use 50,000; 100,000 for quick tests basically.\nall_smiles = load_smiles_data(SMILES_FILE_PATH, num_samples=100000) \n\n# --- SMILES Tokenization ---\n# A simple character-level tokenizer for demonstration.\ndef build_smiles_vocab(smiles_list, max_vocab_size=None):\n    all_chars = set()\n    for smiles in smiles_list:\n        for char in smiles:\n            all_chars.add(char)\n    vocab = sorted(list(all_chars))\n    # Adding special tokens\n    vocab = ['<pad>', '<unk>', '<cls>', '<eos>'] + vocab\n    if max_vocab_size:\n        vocab = vocab[:max_vocab_size]\n    char_to_idx = {char: i for i, char in enumerate(vocab)}\n    idx_to_char = {i: char for i, char in enumerate(vocab)}\n    print(f\"Built vocabulary of size: {len(vocab)}\")\n    return vocab, char_to_idx, idx_to_char\n\nvocab, char_to_idx, idx_to_char = build_smiles_vocab(all_smiles)\nVOCAB_SIZE = len(vocab)\nMAX_SMILES_LEN = 256 # Max sequence length for Transformer.\nMAX_NODES = max_nodes_found      # Maximum number of nodes in any graph in a batch. Adjust based on data.\n\ndef tokenize_smiles(smiles, char_to_idx, max_len):\n    \"\"\"Here we basically plan to convert a SMILES string to a sequence of token IDs.\"\"\"\n    tokens = list(smiles)\n    indexed_tokens = [char_to_idx.get(char, char_to_idx['<unk>']) for char in tokens]\n    \n    # Pad or truncate\n    if len(indexed_tokens) < max_len:\n        padded_tokens = indexed_tokens + [char_to_idx['<pad>']] * (max_len - len(indexed_tokens))\n    else:\n        padded_tokens = indexed_tokens[:max_len]\n    return np.array(padded_tokens, dtype=np.int32)\n\ndef create_smiles_mask(token_ids, pad_token_id):\n    \"\"\"This will create a boolean mask for padded tokens.\"\"\"\n    return tf.cast(token_ids == pad_token_id, tf.bool)\n\n\n# --- SMILES to TensorFlow Graph Conversion ---\n# This is the critical part, transforming SMILES to a graph representation which will be usable by a TensorFlow GNN, specifically sparse tensors for efficiency.\n\n# Defining the atom and bond features\n# These are just example indices for features, along the way we will design specific one-hot encodings or numerical features based on chemical intuition.\nATOM_FEATURES_LIST = [\n    6, 7, 8, 9, 15, 16, 17, 35, 53, # Atomic number (C, N, O, F, P, S, Cl, Br, I)\n    1, 2, 3, 4, # Degree (number of bonds)\n    0, 1, 2, 3, 4, # Hybridization (SP, SP2, SP3, SP3D, SP3D2 as ints)\n    0, 1, # Is aromatic\n    -1, 0, 1, 2, 3, 4 # Formal charge\n]\nNUM_ATOM_FEATURES = len(ATOM_FEATURES_LIST) # we are gonna make it the output dim of our featurizer\n\nBOND_FEATURES_LIST = [\n    Chem.BondType.SINGLE, Chem.BondType.DOUBLE, Chem.BondType.TRIPLE, Chem.BondType.AROMATIC, # Bond types\n    0, 1 # Is conjugated\n]\nNUM_BOND_FEATURES = len(BOND_FEATURES_LIST) # we will also make this the output dim of our featurizer\n\n\ndef atom_to_feature_vector(atom):\n    \"\"\"This will convert an RDKit atom to a feature vector.\"\"\"\n    features = []\n    # Atomic number (one-hot or direct embedding if using learned features)\n    features.append(atom.GetAtomicNum())\n    features.append(atom.GetDegree())\n    features.append(int(atom.GetHybridization())) # Convert enum to int\n    features.append(int(atom.GetIsAromatic()))\n    features.append(atom.GetFormalCharge())\n    return np.array(features, dtype=np.float32)\n\ndef bond_to_feature_vector(bond):\n    \"\"\"converting an RDKit bond to a feature vector.\"\"\"\n    features = []\n    features.append(int(bond.GetBondType()))\n    features.append(int(bond.GetIsConjugated()))\n    return np.array(features, dtype=np.float32)\n\ndef smiles_to_tf_graph(smiles_string):\n    \"\"\"\n    Converts a SMILES string to TensorFlow graph components:\n    node_features, edge_indices, and num_nodes.\n    \"\"\"\n    mol = Chem.MolFromSmiles(smiles_string)\n    if mol is None:\n        return None, None, None\n\n    # Getting node features\n    node_features = [atom_to_feature_vector(atom) for atom in mol.GetAtoms()]\n    if not node_features: \n        return None, None, None\n    node_features = np.array(node_features, dtype=np.float32)\n    num_nodes = len(node_features)\n\n    # Get edge indices (like in the adjacency list format)\n    # RDKit's GetBonds() already gives each bond once\n    edge_indices = []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_indices.append([i, j])\n        edge_indices.append([j, i])  # Adding the reverse edge incase for undirected graph\n\n    if not edge_indices: # for handling the single atom molecules or molecules with no bonds\n        # For a single node we will create a self-loop so it ks not isolated in the graph\n        if num_nodes == 1:\n            edge_indices = [[0, 0]]\n        else:\n            return node_features, tf.zeros((0, 2), dtype=tf.int32), num_nodes # No edges\n\n    edge_indices = np.array(edge_indices, dtype=np.int32)\n\n    num_edges = len(mol.GetBonds()) * 2 # Multiplied by 2 because we add reverse edges\n    if not edge_indices: # If no edges (e.g., single atom or parsing issue)\n        num_edges = 0 # is 0 if no edges were found\n    return node_features, edge_indices, num_nodes, num_edges ","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T18:36:07.770223Z","iopub.execute_input":"2025-06-22T18:36:07.770633Z","iopub.status.idle":"2025-06-22T18:36:19.539037Z","shell.execute_reply.started":"2025-06-22T18:36:07.770600Z","shell.execute_reply":"2025-06-22T18:36:19.534534Z"}},"outputs":[{"name":"stderr","text":"[18:36:07] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] Explicit valence for atom # 1 Si, 8, is greater than permitted\n[18:36:10] Explicit valence for atom # 1 Si, 8, is greater than permitted\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] Explicit valence for atom # 1 Si, 8, is greater than permitted\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] Explicit valence for atom # 1 Si, 8, is greater than permitted\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] Explicit valence for atom # 1 Si, 8, is greater than permitted\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:10] WARNING: not removing hydrogen atom without neighbors\n[18:36:11] Explicit valence for atom # 1 Ge, 8, is greater than permitted\n[18:36:14] Explicit valence for atom # 1 Si, 8, is greater than permitted\n[18:36:14] WARNING: not removing hydrogen atom without neighbors\n[18:36:14] WARNING: not removing hydrogen atom without neighbors\n[18:36:14] Explicit valence for atom # 1 Si, 8, is greater than permitted\n[18:36:14] WARNING: not removing hydrogen atom without neighbors\n[18:36:15] WARNING: not removing hydrogen atom without neighbors\n[18:36:15] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:16] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:17] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:18] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n[18:36:19] WARNING: not removing hydrogen atom without neighbors\n","output_type":"stream"},{"name":"stdout","text":"Maximum nodes found in the first 100000 molecules: 419\nLoaded 100000 SMILES strings.\nBuilt vocabulary of size: 71\n","output_type":"stream"}],"execution_count":52},{"id":"9bb21682","cell_type":"code","source":"\n# We are Defining the featurization function for the dataset map operation\ndef featurize_smiles_and_graph(smiles_string):\n    token_ids = tokenize_smiles(smiles_string.numpy().decode('utf-8'), char_to_idx, MAX_SMILES_LEN)\n    mask = create_smiles_mask(token_ids, char_to_idx['<pad>'])\n\n    node_features, edge_indices, num_nodes = smiles_to_tf_graph(smiles_string.numpy().decode('utf-8'))\n\n    # Handling the cases where graph conversion fails (e.g., invalid smiles)\n    if node_features is None:\n        dummy_edge_indices = tf.zeros((0, 2), dtype=tf.int32)\n        dummy_num_nodes = tf.constant(0, dtype=tf.int32)\n        dummy_num_edges = tf.constant(0, dtype=tf.int32) \n        return dummy_node_features, dummy_edge_indices, dummy_num_nodes, dummy_num_edges, token_ids, mask \n    \n    # We will ensure node_features has consistent shape by padding if necessary for batching\n    # It assumes a maximum number of nodes in any graph.\n    padded_node_features = tf.pad(node_features, [[0, MAX_NODES - num_nodes], [0, 0]])\n    \n    return (tf.constant(padded_node_features, dtype=tf.float32),\n            tf.constant(edge_indices, dtype=tf.int32),\n            tf.constant(num_nodes, dtype=tf.int32),\n            tf.constant(num_edges, dtype=tf.int32),\n            tf.constant(token_ids, dtype=tf.int32),\n            tf.constant(mask, dtype=tf.bool))\n\ndataset = tf.data.Dataset.from_tensor_slices(all_smiles)\n\n# Mapping the featurization function by using tf.py_function for non-TF operations (RDKit)\ndataset = dataset.map(lambda x: tf.py_function(\n    featurize_smiles_and_graph,\n    inp=[x],\n    Tout=(tf.float32, tf.int32, tf.int32, tf.int32, tf.int32, tf.bool) \n), num_parallel_calls=tf.data.AUTOTUNE)\n\n# Filtering out the failed conversions\ndataset = dataset.filter(lambda node_feat, edge_idx, num_nodes, num_edges, token_ids, mask: num_nodes > 0)\n\nBATCH_SIZE_PER_REPLICA = 64 \nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\npadded_shapes = (\n    tf.TensorShape([MAX_NODES, NUM_ATOM_FEATURES]), # node_features\n    tf.TensorShape([None, 2]), # edge_indices (variable length per graph in batch)\n    tf.TensorShape([]),        # num_nodes (scalar per graph)\n    tf.TensorShape([]),        # num_edges (scalar per graph) \n    tf.TensorShape([MAX_SMILES_LEN]), # token_ids\n    tf.TensorShape([MAX_SMILES_LEN])  # mask\n)\npadding_values = (\n    tf.constant(0.0, dtype=tf.float32), # node_features padding\n    tf.constant(0, dtype=tf.int32),     # edge_indices padding\n    tf.constant(0, dtype=tf.int32),     # num_nodes padding\n    tf.constant(0, dtype=tf.int32),     # num_edges padding \n    tf.constant(char_to_idx['<pad>'], dtype=tf.int32), # token_ids padding\n    tf.constant(True, dtype=tf.bool)    # mask padding\n)\n\ndataset = dataset.cache() # We are Caching data after featurization for faster epochs\ndataset = dataset.shuffle(buffer_size=10000) \ndataset = dataset.padded_batch(GLOBAL_BATCH_SIZE, padded_shapes=padded_shapes, padding_values=padding_values, drop_remainder=True)\ndataset = dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T18:36:22.233587Z","iopub.execute_input":"2025-06-22T18:36:22.233937Z","iopub.status.idle":"2025-06-22T18:36:22.525069Z","shell.execute_reply.started":"2025-06-22T18:36:22.233906Z","shell.execute_reply":"2025-06-22T18:36:22.520131Z"}},"outputs":[],"execution_count":53},{"id":"dfb6f6e4","cell_type":"markdown","source":"# --- Creating tf.data.Dataset for TPU ---","metadata":{}},{"id":"ce3cc0f8","cell_type":"markdown","source":"# --- Model Architecture (TensorFlow/Keras) ---","metadata":{}},{"id":"63e7bcbe","cell_type":"code","source":"# GIN Layer (as a Custom Keras Layer) we are doing it as this implements the core GIN aggregation as a Keras layer suitable for sparse tensors and TPU\nclass GINLayer(layers.Layer):\n    def __init__(self, output_dim, activation=None, **kwargs):\n        super(GINLayer, self).__init__(**kwargs)\n        self.output_dim = output_dim\n        self.mlp = keras.Sequential([\n            layers.Dense(output_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n        self.epsilon = self.add_weight(name='epsilon', shape=(),\n                                       initializer=keras.initializers.Constant(0.0),\n                                       trainable=True)\n        self.activation = keras.activations.get(activation)\n\n    def call(self, inputs):\n        node_features, edge_indices_batch, num_nodes_batch = inputs\n        \n        edge_values = tf.ones(tf.shape(edge_indices_batch)[0], dtype=tf.float32)\n        \n        total_nodes_in_batch = tf.shape(node_features)[0]\n        adj_shape = tf.cast([total_nodes_in_batch, total_nodes_in_batch], dtype=tf.int64)\n\n        adj_sparse = tf.sparse.SparseTensor(indices=tf.cast(edge_indices_batch, tf.int64),\n                                            values=edge_values,\n                                            dense_shape=adj_shape)\n        \n        # Sum of neighbor features: (A * H)\n        neighbor_sum = tf.sparse.sparse_dense_matmul(adj_sparse, node_features)\n\n        # GIN update: MLP((1 + epsilon) * H + Sum(Neighbors))\n        combined_features = (1 + self.epsilon) * node_features + neighbor_sum\n        output = self.mlp(combined_features)\n\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0][0], self.output_dim # (batch_size * max_nodes_per_graph, output_dim)\n\nclass GINEncoder(keras.Model):\n    def __init__(self, num_layers, hidden_dim, num_node_features, **kwargs): \n        super(GINEncoder, self).__init__(**kwargs)\n\n        self.initial_mlp = keras.Sequential([\n            layers.Dense(hidden_dim, activation='relu'),\n            layers.Dense(hidden_dim) \n        ])\n        \n        self.gin_layers = []\n        # Input layer for GIN\n        self.gin_layers.append(GINLayer(hidden_dim, activation='relu'))\n        self.gin_layers.append(layers.BatchNormalization())\n\n        for i in range(num_layers - 1): # Start from 1 as first layer is input\n            self.gin_layers.append(GINLayer(hidden_dim, activation='relu' if i < num_layers - 2 else None))\n            self.gin_layers.append(layers.BatchNormalization()) # Add BatchNorm\n\n    def call(self, inputs):\n        node_features, edge_indices, num_nodes = inputs\n\n        x = self.initial_mlp(node_features) # Applying initial transformation\n        \n        for i in range(len(self.gin_layers)): # Iterate through paired GIN layers and BatchNorms\n            x = self.gin_layers[i]((x, edge_indices, num_nodes)) # Pass inputs to GINLayer\n            x = self.bns[i](x) # Apply BatchNorm\n        \n        batch_size = tf.shape(node_features)[0] // MAX_NODES\n        \n        # Reshaping to (batch_size, MAX_NODES, hidden_dim)\n        x_reshaped = tf.reshape(x, (batch_size, MAX_NODES, self.gin_layers[-2].output_dim)) # Using last GIN layer output dim\n        \n        # Creating a mask for valid nodes in each graph\n        # `num_nodes` is the actual number of nodes *before* padding for each graph in the batch\n        # (GLOBAL_BATCH_SIZE,)\n        \n        # We use `tf.sequence_mask` to create a boolean mask\n        sequence_mask = tf.sequence_mask(num_nodes, maxlen=MAX_NODES, dtype=tf.float32) \n        sequence_mask = tf.expand_dims(sequence_mask, axis=-1) \n        \n        # Applying mask and sum\n        masked_x = x_reshaped * sequence_mask\n        graph_embedding = tf.reduce_sum(masked_x, axis=1) # Sum pooling\n        \n        return graph_embedding \n\nclass TransformerEncoder(keras.Model):\n    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, max_seq_len, dropout_rate=0.1, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.token_embedding = layers.Embedding(vocab_size, embed_dim)\n        self.positional_embedding = self.add_weight(\n            name=\"pos_embed\",\n            shape=(1, max_seq_len, embed_dim),\n            initializer=\"random_normal\",\n            trainable=True\n        )\n\n        self.encoder_layers = []\n        for _ in range(num_layers):\n            self.encoder_layers.append([\n                layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout_rate),\n                layers.LayerNormalization(epsilon=1e-6),\n                layers.Dense(embed_dim * 4, activation=\"relu\"),\n                layers.Dense(embed_dim),\n                layers.LayerNormalization(epsilon=1e-6),\n            ])\n        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, inputs, training=False, mask=None):\n        token_ids, padding_mask = inputs # padding_mask is boolean (True for padded)\n        \n        x = self.token_embedding(token_ids)\n        x = x + self.positional_embedding[:, :tf.shape(x)[1], :]\n\n        for i, (attention, norm1, ff_dense1, ff_dense2, norm2) in enumerate(self.encoder_layers):\n            # Attention block\n            attn_output = attention(x, x, attention_mask=padding_mask, training=training)\n            x = norm1(x + attn_output) # Add & Norm\n\n            # Feed-forward block\n            ff_output = ff_dense2(ff_dense1(x))\n            x = norm2(x + ff_output) # Add & Norm\n        \n        # Global pooling: mask out padded tokens before mean pooling\n\n        expanded_padding_mask = tf.cast(tf.expand_dims(padding_mask, axis=-1), dtype=x.dtype)\n        \n        # Invert the mask logic: 1.0 for non-padded, 0.0 for padded\n        non_padded_mask = 1.0 - expanded_padding_mask\n        \n        # Apply mask: so we will set padded embeddings to 0\n        x_masked = x * non_padded_mask\n        \n        # Sum along sequence dimension\n        sum_embeddings = tf.reduce_sum(x_masked, axis=1)\n        \n        # Counting non-padded elements per sequence\n        non_padded_len = tf.reduce_sum(non_padded_mask, axis=1)\n        \n        # Mean pooling (also avoiding division by zero for fully padded sequences)\n        smiles_embedding = sum_embeddings / (non_padded_len + 1e-9) # Adding epsilon to avoid div by zero\n        \n        return self.final_norm(smiles_embedding)\n\n\nclass ProjectionHead(keras.Model):\n    def __init__(self, input_dim, output_dim, hidden_dim=256, **kwargs):\n        super(ProjectionHead, self).__init__(**kwargs)\n        self.net = keras.Sequential([\n            layers.Dense(hidden_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n\n    def call(self, x):\n        return self.net(x)\n\nclass GRASPModel(keras.Model):\n    def __init__(self, gin_config, transformer_config, projection_dim, **kwargs):\n        super(GRASPModel, self).__init__(**kwargs)\n        self.gin_encoder = GINEncoder(**gin_config)\n        self.transformer_encoder = TransformerEncoder(**transformer_config)\n        \n        self.graph_projection_head = ProjectionHead(gin_config['hidden_dim'], projection_dim)\n        self.smiles_projection_head = ProjectionHead(transformer_config['embed_dim'], projection_dim)\n    \n    def call(self, inputs, training=False):\n        node_features, edge_indices_padded, num_nodes, num_edges, token_ids, smiles_mask = inputs \n         \n        batch_size = tf.shape(node_features)[0]\n        \n        # --- Handling Edge Indices for GINLayer ---\n        # Creating a mask to identify valid edges (non-padded ones)\n        edge_mask = tf.sequence_mask(num_edges, maxlen=tf.shape(edge_indices_padded)[1], dtype=tf.bool)\n         \n        # Filtering out padded edges, This will bascially flatten the valid edges across the entire batch\n        valid_edge_indices = tf.boolean_mask(edge_indices_padded, edge_mask)\n        \n        # Creating global node offsets for each graph in the batch\n        # This transforms local node IDs (0 to MAX_NODES-1) into global IDs across the flattened node list\n        node_offsets_for_edges = tf.range(batch_size) * MAX_NODES \n        # Expanding and tiling this offset to apply to each edge\n        node_offsets_for_edges = tf.expand_dims(node_offsets_for_edges, axis=1) \n        node_offsets_for_edges_expanded = tf.boolean_mask(tf.tile(node_offsets_for_edges, [1, tf.shape(edge_indices_padded)[1]]), edge_mask)\n        node_offsets_for_edges_expanded = tf.expand_dims(node_offsets_for_edges_expanded, axis=-1) \n        \n        # Applying offsets to get global edge indices\n        global_edge_indices_filtered = valid_edge_indices + tf.cast(node_offsets_for_edges_expanded, dtype=tf.int32)\n        \n        # Encoding graphs\n        graph_embeddings_raw = self.gin_encoder((node_features, global_edge_indices_filtered, num_nodes), training=training)\n        graph_embeddings_projected = self.graph_projection_head(graph_embeddings_raw, training=training)\n        \n        # Encode SMILES\n        smiles_embeddings_raw = self.transformer_encoder((token_ids, smiles_mask), training=training)\n        smiles_embeddings_projected = self.smiles_projection_head(smiles_embeddings_raw, training=training)\n        \n        # Apply L2 normalization to projected embeddings for InfoNCE loss\n        graph_embeddings_projected = tf.linalg.normalize(graph_embeddings_projected, axis=1)[0]\n        smiles_embeddings_projected = tf.linalg.normalize(smiles_embeddings_projected, axis=1)[0]\n        \n        return graph_embeddings_projected, smiles_embeddings_projected","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T18:36:25.264098Z","iopub.execute_input":"2025-06-22T18:36:25.264438Z","iopub.status.idle":"2025-06-22T18:36:25.298803Z","shell.execute_reply.started":"2025-06-22T18:36:25.264411Z","shell.execute_reply":"2025-06-22T18:36:25.294596Z"}},"outputs":[],"execution_count":54},{"id":"2782bc8a","cell_type":"markdown","source":"# --- Contrastive Loss (InfoNCE) ---","metadata":{}},{"id":"d09af71b","cell_type":"code","source":"class InfoNCELoss(keras.losses.Loss):\n    def __init__(self, temperature=0.07, name='info_nce_loss', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.temperature = temperature\n\n    @tf.function\n    def call(self, graph_embeddings, smiles_embeddings):\n\n        # Cosine similarity matrix (logits)\n        # S_ij = sim(g_i, s_j)\n        logits = tf.matmul(graph_embeddings, smiles_embeddings, transpose_b=True) / self.temperature\n        \n        # Creating labels: diagonal elements are positive pairs\n        batch_size = tf.shape(logits)[0]\n        labels = tf.eye(batch_size) # (batch_size, batch_size)\n\n        # Calculating cross-entropy for graph->SMILES and SMILES->graph\n        # loss_g_s: how well graph embeddings predict their corresponding SMILES\n        loss_g_s = tf.keras.losses.categorical_crossentropy(labels, logits, from_logits=True)\n        \n        # loss_s_g: how well SMILES embeddings predict their corresponding graphs\n        loss_s_g = tf.keras.losses.categorical_crossentropy(labels, tf.transpose(logits), from_logits=True)\n\n        # Total loss is the average of both directions\n        total_loss = (loss_g_s + loss_s_g) / 2\n        \n        # Reduce mean over the batch\n        return tf.reduce_mean(total_loss)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T18:36:29.477851Z","iopub.execute_input":"2025-06-22T18:36:29.478221Z","iopub.status.idle":"2025-06-22T18:36:29.491754Z","shell.execute_reply.started":"2025-06-22T18:36:29.478174Z","shell.execute_reply":"2025-06-22T18:36:29.486912Z"}},"outputs":[],"execution_count":55},{"id":"91840c15","cell_type":"markdown","source":"# --- Training Loop ---","metadata":{}},{"id":"131fc2e5","cell_type":"code","source":"PROJECTION_DIM = 128 # Dimension of the shared embedding space\nHIDDEN_DIM_GIN = 256 \nNUM_GIN_LAYERS = 3   \nEMBED_DIM_TRANSFORMER = 256 \nNUM_TRANSFORMER_HEADS = 8\nNUM_TRANSFORMER_LAYERS = 3\n\ngin_config = {\n    'num_layers': NUM_GIN_LAYERS,\n    'hidden_dim': HIDDEN_DIM_GIN,\n    # Atom features from featurization. This is the input_dim for the first GIN layer.\n    # It must match the output of `atom_to_feature_vector`.\n    # 'num_node_features': len(atom_to_feature_vector(Chem.Atom(6))) # Using a dummy atom to get feature count\n    'num_node_features': 5 \n}\n\ntransformer_config = {\n    'vocab_size': VOCAB_SIZE,\n    'embed_dim': EMBED_DIM_TRANSFORMER,\n    'num_heads': NUM_TRANSFORMER_HEADS,\n    'num_layers': NUM_TRANSFORMER_LAYERS,\n    'max_seq_len': MAX_SMILES_LEN\n}\n\n# Defining the training step function\n@tf.function\ndef train_step(inputs):\n    with tf.GradientTape() as tape:\n        graph_embeddings, smiles_embeddings = model(inputs, training=True)\n        loss = info_nce_loss(graph_embeddings, smiles_embeddings)\n        \n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss\n\n# Instantiating model, loss, and optimizer within the TPU strategy scope\nwith strategy.scope():\n    model = GRASPModel(gin_config, transformer_config, PROJECTION_DIM)\n    info_nce_loss = InfoNCELoss(temperature=0.07) # Adjust temperature as needed\n    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n\n    model.compile(optimizer=optimizer, loss=info_nce_loss)\n\nEPOCHS = 5 \nsteps_per_epoch = tf.data.experimental.cardinality(dataset).numpy()\n\nprint(f\"\\nStarting pre-training for {EPOCHS} epochs...\")\nprint(f\"Steps per epoch: {steps_per_epoch}\")\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n    total_loss = 0.0\n    num_batches = 0\n\n    for batch_inputs in dataset:\n        per_replica_losses = strategy.run(train_step, args=(batch_inputs,))\n        batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n        total_loss += batch_loss\n        num_batches += 1\n        \n        if num_batches % 10 == 0:\n            print(f\"  Batch {num_batches}/{steps_per_epoch}, Loss: {batch_loss:.4f}\", end='\\r')\n    \n    avg_loss = total_loss / num_batches\n    print(f\"Epoch {epoch + 1} finished. Average Loss: {avg_loss:.4f}\")\n\nprint(\"\\nPre-training complete!\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T18:36:31.857954Z","iopub.execute_input":"2025-06-22T18:36:31.858304Z","iopub.status.idle":"2025-06-22T18:36:32.024935Z","shell.execute_reply.started":"2025-06-22T18:36:31.858275Z","shell.execute_reply":"2025-06-22T18:36:32.018894Z"}},"outputs":[{"name":"stdout","text":"\nStarting pre-training for 5 epochs...\nSteps per epoch: -2\n\nEpoch 1/5\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[56], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     53\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_inputs \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     56\u001b[0m     per_replica_losses \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mrun(train_step, args\u001b[38;5;241m=\u001b[39m(batch_inputs,))\n\u001b[1;32m     57\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mreduce(tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mReduceOp\u001b[38;5;241m.\u001b[39mSUM, per_replica_losses, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_6_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:31 transformation with iterator: Iterator::Root::Prefetch::PaddedBatchV2::Shuffle::MemoryCacheImpl::Filter::ParallelMapV2: ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_10/1664364634.py\", line 6, in featurize_smiles_and_graph\n    node_features, edge_indices, num_nodes = smiles_to_tf_graph(smiles_string.numpy().decode('utf-8'))\n\n  File \"/tmp/ipykernel_10/1537646748.py\", line 145, in smiles_to_tf_graph\n    if not edge_indices: # If no edges (e.g., single atom or parsing issue)\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "],"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_6_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:31 transformation with iterator: Iterator::Root::Prefetch::PaddedBatchV2::Shuffle::MemoryCacheImpl::Filter::ParallelMapV2: ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_10/1664364634.py\", line 6, in featurize_smiles_and_graph\n    node_features, edge_indices, num_nodes = smiles_to_tf_graph(smiles_string.numpy().decode('utf-8'))\n\n  File \"/tmp/ipykernel_10/1537646748.py\", line 145, in smiles_to_tf_graph\n    if not edge_indices: # If no edges (e.g., single atom or parsing issue)\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ","output_type":"error"}],"execution_count":56},{"id":"fb53c3b9","cell_type":"markdown","source":"# --- Saving the model ---","metadata":{}},{"id":"dd015d93","cell_type":"code","source":"# To save just the encoders:\n# tf.saved_model.save(model.gin_encoder, 'gin_encoder_pretrained')\n# tf.saved_model.save(model.transformer_encoder, 'transformer_encoder_pretrained')\n# print(\"Encoders saved.\")\n\n\nmodel.save('grasp_pretrained_model')\nprint(\"Model saved to 'grasp_pretrained_model' directory.\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:45:24.993678Z","iopub.status.idle":"2025-06-22T17:45:24.996239Z","shell.execute_reply.started":"2025-06-22T17:45:24.994622Z","shell.execute_reply":"2025-06-22T17:45:24.994637Z"}},"outputs":[],"execution_count":null}]}