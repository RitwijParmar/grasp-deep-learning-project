{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:10:03.614812Z",
     "iopub.status.busy": "2025-07-04T06:10:03.614494Z",
     "iopub.status.idle": "2025-07-04T06:39:10.349820Z",
     "shell.execute_reply": "2025-07-04T06:39:10.348917Z",
     "shell.execute_reply.started": "2025-07-04T06:10:03.614791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting Linear Probing for Dataset: esol \n",
      "\n",
      " Starting Training of the Linear Head \n",
      "Epoch 1/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - mae: 783.9236 - rmse: 6409.7808 - loss: -352.4199 - val_loss: 387.2663\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - mae: 776.0024 - rmse: 7425.4927 - loss: 157.4381 - val_loss: -843.6974\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 1604.3159 - rmse: 26026.7344 - loss: -1633.7240 - val_loss: 121.7905\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 1114.4108 - rmse: 10660.2549 - loss: -55.7649 - val_loss: 613.6386\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 737.4864 - rmse: 6891.5420 - loss: 555.0538 - val_loss: 645.5946\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - mae: 676.8101 - rmse: 6999.9136 - loss: 455.9750 - val_loss: 407.0562\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 437.2980 - rmse: 3558.3555 - loss: 215.8057 - val_loss: 63.5081\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 343.0542 - rmse: 2471.1860 - loss: -158.9319 - val_loss: -29.0267\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - mae: 275.1209 - rmse: 1515.6744 - loss: -16.9016 - val_loss: -57.0764\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 233.9207 - rmse: 1383.4386 - loss: -61.1369 - val_loss: -95.6243\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 309.4677 - rmse: 2307.9939 - loss: 30.8316 - val_loss: -136.4119\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - mae: 458.6295 - rmse: 6345.9653 - loss: 79.4089 - val_loss: -961.3973\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 514.5820 - rmse: 3290.1870 - loss: -453.5226 - val_loss: -1266.0341\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 552.7969 - rmse: 3572.0439 - loss: -521.0621 - val_loss: -1125.8931\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 1422.8396 - rmse: 13292.6016 - loss: -1382.2163 - val_loss: -317.1551\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 278.4368 - rmse: 1628.3420 - loss: -22.5044 - val_loss: -189.8180\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - mae: 280.6785 - rmse: 1632.8240 - loss: 40.6840 - val_loss: -192.2118\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 211.9339 - rmse: 1039.2483 - loss: -101.2584 - val_loss: -234.5767\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 241.0208 - rmse: 1133.7369 - loss: -109.8340 - val_loss: -266.9701\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 235.9315 - rmse: 1800.0704 - loss: -57.7696 - val_loss: -466.9827\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 654.4521 - rmse: 10434.7773 - loss: 96.1840 - val_loss: -749.9081\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 425.3844 - rmse: 2790.0239 - loss: -405.6790 - val_loss: -856.2197\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - mae: 427.4639 - rmse: 2750.4661 - loss: -406.3339 - val_loss: -595.0934\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 415.2637 - rmse: 4241.7471 - loss: -150.4903 - val_loss: -685.5924\n",
      "Epoch 25/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 540.2358 - rmse: 3695.1982 - loss: -509.5523 - val_loss: -870.8192\n",
      "Epoch 26/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 383.2570 - rmse: 2566.7668 - loss: -354.8443 - val_loss: -787.6630\n",
      "Epoch 27/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 517.3256 - rmse: 3288.0166 - loss: -495.0591 - val_loss: -511.8828\n",
      "Epoch 28/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - mae: 337.9387 - rmse: 3236.4189 - loss: -300.6505 - val_loss: -100.9461\n",
      "Epoch 29/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 535.7067 - rmse: 6601.6768 - loss: 260.9109 - val_loss: 387.3781\n",
      "Epoch 30/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - mae: 394.8282 - rmse: 2366.7046 - loss: 113.9674 - val_loss: -289.6647\n",
      "Epoch 31/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 209.2428 - rmse: 789.4392 - loss: -157.7060 - val_loss: -461.2389\n",
      "Epoch 32/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - mae: 710.4000 - rmse: 5904.8516 - loss: -720.6981 - val_loss: -253.7674\n",
      "Epoch 33/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 904.5374 - rmse: 10253.5264 - loss: -621.6385 - val_loss: 770.0157\n",
      "Epoch 34/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 1091.8499 - rmse: 8337.7188 - loss: 804.6705 - val_loss: 460.2376\n",
      "Epoch 35/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 441.8607 - rmse: 3446.0637 - loss: 206.3509 - val_loss: 267.2219\n",
      "Epoch 36/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 431.1153 - rmse: 5209.2197 - loss: 237.4668 - val_loss: 48.6149\n",
      "Epoch 37/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - mae: 344.6153 - rmse: 2742.4238 - loss: 38.5582 - val_loss: -39.8172\n",
      "Epoch 38/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 210.6672 - rmse: 1608.4315 - loss: -190.1555 - val_loss: 55.8925\n",
      "Epoch 39/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 1076.9988 - rmse: 13884.2305 - loss: 868.8659 - val_loss: -547.3047\n",
      "Epoch 40/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 587.8987 - rmse: 5649.6221 - loss: 102.8882 - val_loss: -1449.5332\n",
      "Epoch 41/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 730.5960 - rmse: 5499.7964 - loss: -704.2120 - val_loss: -1377.6982\n",
      "Epoch 42/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 592.2454 - rmse: 4397.9585 - loss: -365.5926 - val_loss: -765.6262\n",
      "Epoch 43/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 234.7780 - rmse: 1112.0551 - loss: -154.6521 - val_loss: -492.9589\n",
      "Epoch 44/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 297.0349 - rmse: 1533.6351 - loss: -282.0966 - val_loss: -334.5697\n",
      "Epoch 45/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - mae: 422.2220 - rmse: 3849.0356 - loss: 204.7398 - val_loss: -396.8958\n",
      "Epoch 46/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - mae: 364.5803 - rmse: 3476.6182 - loss: 17.7112 - val_loss: -740.3087\n",
      "Epoch 47/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 599.6828 - rmse: 5762.6553 - loss: -612.7806 - val_loss: -414.8058\n",
      "Epoch 48/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 221.7247 - rmse: 1603.6288 - loss: -44.7373 - val_loss: -223.6879\n",
      "Epoch 49/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - mae: 324.3288 - rmse: 2614.4238 - loss: 53.1061 - val_loss: -385.0618\n",
      "Epoch 50/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - mae: 249.2064 - rmse: 1930.6444 - loss: -236.4368 - val_loss: -342.4970\n",
      "\n",
      " Training Finished \n",
      "\n",
      " Final Performance on Unseen Test Data \n",
      "  Final Test loss: -55.1849\n",
      "  Final Test rmse: 87.1586\n",
      "  Final Test mae: 55.1139\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#  CONFIGURATION FOR ESOL \n",
    "DATASET_NAME = 'esol'\n",
    "MOLECULENET_PATH = '/kaggle/input/moleculenet-tfrecords-final/moleculenet_tfrecords_final/'\n",
    "GRASP_CHECKPOINT_PATH = '/kaggle/input/pretraining-checkpoints/pretraining_checkpoints/'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_NODES = 419\n",
    "NUM_ATOM_FEATURES = 5\n",
    "\n",
    "#  DATA PIPELINE \n",
    "DUMMY_SMILES_FOR_VOCAB = [\"C\", \"N\", \"O\", \"F\", \"P\", \"S\", \"Cl\", \"Br\", \"I\", \"c\", \"n\", \"=\", \"#\", \"(\", \")\", \"[\", \"]\", \"@\", \"+\", \"-\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"H\", \"B\", \"b\", \"K\", \"k\", \"L\", \"l\", \"M\", \"m\", \"R\", \"r\", \"X\", \"x\", \"Y\", \"y\", \"Z\", \"z\"] \n",
    "VOCAB = ['<pad>', '<unk>', '<cls>', '<eos>'] + sorted(list(set(\"\".join(DUMMY_SMILES_FOR_VOCAB))))\n",
    "CHAR_TO_IDX = {char: i for i, char in enumerate(VOCAB)}\n",
    "\n",
    "def parse_fn(example):\n",
    "    feature_description = {\n",
    "        'atom_features': tf.io.FixedLenFeature([], tf.string), 'edge_index': tf.io.FixedLenFeature([], tf.string),\n",
    "        'num_nodes': tf.io.FixedLenFeature([], tf.string), 'token_ids': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    atom_features = tf.io.parse_tensor(example['atom_features'], out_type=tf.float32)\n",
    "    edge_index = tf.io.parse_tensor(example['edge_index'], out_type=tf.int32)\n",
    "    num_nodes = tf.io.parse_tensor(example['num_nodes'], out_type=tf.int32)\n",
    "    token_ids = tf.io.parse_tensor(example['token_ids'], out_type=tf.int32)\n",
    "    label = tf.io.parse_tensor(example['label'], out_type=tf.float32)\n",
    "    # For ESOL, the label shape is (1,)\n",
    "    label = tf.reshape(label, [1])\n",
    "    return (atom_features, edge_index, num_nodes, token_ids), label\n",
    "\n",
    "@tf.function\n",
    "def prepare_batch_for_model(features, label):\n",
    "    atom_features, edge_index, num_nodes, token_ids = features\n",
    "    atom_features_flat = tf.reshape(atom_features, (BATCH_SIZE * MAX_NODES, NUM_ATOM_FEATURES))\n",
    "    num_nodes_squeezed = tf.squeeze(num_nodes, axis=-1)\n",
    "    node_offsets = tf.cumsum(num_nodes_squeezed, exclusive=True)\n",
    "    is_real_edge_mask = edge_index[:, :, 0] >= 0\n",
    "    edge_batch_ids = tf.where(is_real_edge_mask)[:, 0]\n",
    "    edge_batch_ids = tf.cast(edge_batch_ids, dtype=tf.int32)\n",
    "    edge_offsets = tf.gather(node_offsets, edge_batch_ids)\n",
    "    real_edges = tf.boolean_mask(edge_index, is_real_edge_mask)\n",
    "    global_edge_index = real_edges + tf.expand_dims(edge_offsets, axis=-1)\n",
    "    padding_mask = (token_ids != CHAR_TO_IDX['<pad>'])\n",
    "    model_inputs = {\n",
    "        'atom_features_input': atom_features_flat, 'edge_index_input': global_edge_index,\n",
    "        'num_nodes_input': num_nodes_squeezed, 'token_ids_input': token_ids,\n",
    "        'padding_mask_input': padding_mask\n",
    "    }\n",
    "    return model_inputs, label\n",
    "\n",
    "def create_dataset(file_pattern, should_shuffle=False):\n",
    "    files = glob.glob(file_pattern)\n",
    "    if not files: return None\n",
    "    dataset = tf.data.TFRecordDataset(files, num_parallel_reads=tf.data.AUTOTUNE).map(parse_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if should_shuffle: dataset = dataset.shuffle(buffer_size=1024)\n",
    "    # The label shape for padded_batch is now hardcoded to 1 for ESOL\n",
    "    dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=((tf.TensorShape([MAX_NODES, NUM_ATOM_FEATURES]), tf.TensorShape([None, 2]), tf.TensorShape([1]), tf.TensorShape([256])), tf.TensorShape([1])), drop_remainder=True)\n",
    "    dataset = dataset.map(prepare_batch_for_model, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "#  Subclassed keras.Model \n",
    "class GraspLinearProbeModel(keras.Model):\n",
    "    def __init__(self, checkpoint_path, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gin_model = tf.saved_model.load(os.path.join(checkpoint_path, 'gin_encoder_best'))\n",
    "        self.transformer_model = tf.saved_model.load(os.path.join(checkpoint_path, 'transformer_encoder_best'))\n",
    "        self.gin_function = self.gin_model.signatures['serving_default']\n",
    "        self.transformer_function = self.transformer_model.signatures['serving_default']\n",
    "        # The head now has 1 output unit and a linear activation for regression\n",
    "        self.head = layers.Dense(1, activation='linear')\n",
    "        self.concat = layers.Concatenate()\n",
    "        \n",
    "    def call(self, data, training=False):\n",
    "        atom_feats, edge_index, num_nodes, token_ids, padding_mask = (\n",
    "            data['atom_features_input'], data['edge_index_input'], data['num_nodes_input'],\n",
    "            data['token_ids_input'], data['padding_mask_input']\n",
    "        )\n",
    "        edge_index_float = tf.cast(edge_index, tf.float32)\n",
    "        num_nodes_float = tf.cast(num_nodes, tf.float32)\n",
    "        token_ids_float = tf.cast(token_ids, tf.float32)\n",
    "        padding_mask_float = tf.cast(padding_mask, tf.float32)\n",
    "        \n",
    "        graph_embedding = self.gin_function(inputs=atom_feats, inputs_1=edge_index_float, inputs_2=num_nodes_float)\n",
    "        smiles_embedding = self.transformer_function(inputs=token_ids_float, inputs_1=padding_mask_float)\n",
    "        \n",
    "        concatenated_embeddings = self.concat([graph_embedding['output_0'], smiles_embedding['output_0']])\n",
    "        return self.head(concatenated_embeddings)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        inputs, y_true = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(y_true, y_pred, regularization_losses=self.losses)\n",
    "            \n",
    "        trainable_vars = self.head.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        inputs, y_true = data\n",
    "        y_pred = self(inputs, training=False)\n",
    "        self.compiled_loss(y_true, y_pred, regularization_losses=self.losses)\n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "#  Main Execution \n",
    "def run_linear_probing():\n",
    "    print(f\" Starting Linear Probing for Dataset: {DATASET_NAME} \")\n",
    "    \n",
    "    model = GraspLinearProbeModel(GRASP_CHECKPOINT_PATH)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    # compiling the model with regression loss and metrics\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                           tf.keras.metrics.MeanAbsoluteError(name='mae')])\n",
    "    \n",
    "    train_ds = create_dataset(os.path.join(MOLECULENET_PATH, f'{DATASET_NAME.lower()}_train.tfrecord'), should_shuffle=True)\n",
    "    valid_ds = create_dataset(os.path.join(MOLECULENET_PATH, f'{DATASET_NAME.lower()}_valid.tfrecord'))\n",
    "    test_ds = create_dataset(os.path.join(MOLECULENET_PATH, f'{DATASET_NAME.lower()}_test.tfrecord'))\n",
    "    if not train_ds: raise ValueError(f\"Training TFRecord not found for {MOLECULENET_PATH}\")\n",
    "\n",
    "    print(\"\\n Starting Training of the Linear Head \")\n",
    "    model.fit(train_ds, epochs=EPOCHS, validation_data=valid_ds, verbose=1)\n",
    "    \n",
    "    print(\"\\n Training Finished \")\n",
    "    print(\"\\n Final Performance on Unseen Test Data \")\n",
    "    \n",
    "    model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "    for metric in model.metrics:\n",
    "        result = metric.result()\n",
    "        # Check if the result is a dictionary (which happens for some metrics)\n",
    "        if isinstance(result, dict):\n",
    "            for key, value in result.items():\n",
    "                print(f\"  Final Test {key}: {value.numpy():.4f}\")\n",
    "        else:\n",
    "            print(f\"  Final Test {metric.name}: {result.numpy():.4f}\")\n",
    "\n",
    "run_linear_probing()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7796043,
     "sourceId": 12364870,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7797008,
     "sourceId": 12366455,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
