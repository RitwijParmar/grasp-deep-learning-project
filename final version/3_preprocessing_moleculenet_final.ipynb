{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install deepchem","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T23:28:38.484626Z","iopub.execute_input":"2025-07-03T23:28:38.484963Z","iopub.status.idle":"2025-07-03T23:28:47.900572Z","shell.execute_reply.started":"2025-07-03T23:28:38.484939Z","shell.execute_reply":"2025-07-03T23:28:47.899398Z"}},"outputs":[{"name":"stdout","text":"Collecting deepchem\n  Downloading deepchem-2.8.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.5.0)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deepchem) (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.2.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.13.1)\nRequirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.15.2)\nCollecting rdkit (from deepchem)\n  Downloading rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->deepchem) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->deepchem) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->deepchem) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->deepchem) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->deepchem) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->deepchem) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2025.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit->deepchem) (11.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepchem) (3.6.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->deepchem) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->deepchem) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->deepchem) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->deepchem) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->deepchem) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->deepchem) (2024.2.0)\nDownloading deepchem-2.8.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl (34.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit, deepchem\nSuccessfully installed deepchem-2.8.0 rdkit-2025.3.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nimport deepchem as dc\nimport numpy as np\nfrom rdkit import Chem\nfrom rdkit import rdBase\nimport os\nfrom tqdm.auto import tqdm\n\n# Suppress non-critical RDKit messages\nrdBase.DisableLog('rdApp.warning')\nrdBase.DisableLog('rdApp.error')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-03T23:28:47.902440Z","iopub.execute_input":"2025-07-03T23:28:47.902753Z","iopub.status.idle":"2025-07-03T23:29:08.373510Z","shell.execute_reply.started":"2025-07-03T23:28:47.902725Z","shell.execute_reply":"2025-07-03T23:29:08.372373Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- CONFIGURATION ---\n# List of MoleculeNet datasets you want to process\nDATASET_NAMES = ['Tox21', 'BBBP', 'ESOL']\n\n# Parameters that MUST match your pre-training setup\nMAX_SMILES_LEN = 256\nMAX_NODES = 419\nNUM_ATOM_FEATURES = 5\n\n# Output directory for the final, correct TFRecord files\nOUTPUT_DIR = 'moleculenet_tfrecords_final'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# --- SINGLE SOURCE OF TRUTH FOR VOCABULARY ---\n# This vocabulary is identical to your pre-training notebook and must be used everywhere.\nDUMMY_SMILES_FOR_VOCAB = [\"C\", \"N\", \"O\", \"F\", \"P\", \"S\", \"Cl\", \"Br\", \"I\", \"c\", \"n\", \"=\", \"#\", \"(\", \")\", \"[\", \"]\", \"@\", \"+\", \"-\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"H\", \"B\", \"b\", \"K\", \"k\", \"L\", \"l\", \"M\", \"m\", \"R\", \"r\", \"X\", \"x\", \"Y\", \"y\", \"Z\", \"z\"] \nVOCAB = ['<pad>', '<unk>', '<cls>', '<eos>'] + sorted(list(set(\"\".join(DUMMY_SMILES_FOR_VOCAB))))\nCHAR_TO_IDX = {char: i for i, char in enumerate(VOCAB)}\nprint(f\"Using a consistent vocabulary of size: {len(VOCAB)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T23:29:08.375384Z","iopub.execute_input":"2025-07-03T23:29:08.376680Z","iopub.status.idle":"2025-07-03T23:29:08.387800Z","shell.execute_reply.started":"2025-07-03T23:29:08.376649Z","shell.execute_reply":"2025-07-03T23:29:08.386272Z"}},"outputs":[{"name":"stdout","text":"Using a consistent vocabulary of size: 49\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def tokenize_smiles(smiles, max_len):\n    \"\"\"Converts a SMILES string to a padded sequence of token IDs using the fixed vocabulary.\"\"\"\n    # Use CHAR_TO_IDX.get() to handle unknown characters gracefully by mapping them to '<unk>'\n    indexed_tokens = [CHAR_TO_IDX.get(char, CHAR_TO_IDX['<unk>']) for char in smiles]\n    \n    if len(indexed_tokens) > max_len:\n        indexed_tokens = indexed_tokens[:max_len]\n        \n    padded_tokens = indexed_tokens + [CHAR_TO_IDX['<pad>']] * (max_len - len(indexed_tokens))\n    return np.array(padded_tokens, dtype=np.int32)\n\n\n# --- GRAPH FEATURIZER (From your pre-training notebook) ---\ndef atom_to_feature_vector(atom):\n    \"\"\"Generates a feature vector for a single atom.\"\"\"\n    return np.array([\n        atom.GetAtomicNum(),\n        atom.GetDegree(),\n        int(atom.GetHybridization()),\n        int(atom.GetIsAromatic()),\n        atom.GetFormalCharge()\n    ], dtype=np.float32)\n\ndef smiles_to_graph_and_tokens(smiles_string, max_nodes, max_len):\n    mol = Chem.MolFromSmiles(smiles_string)\n    if not mol or mol.GetNumAtoms() > max_nodes:\n        return None\n\n    # Graph features\n    atom_features = np.array([atom_to_feature_vector(atom) for atom in mol.GetAtoms()])\n    num_nodes = len(atom_features)\n    padded_atom_features = np.zeros((max_nodes, NUM_ATOM_FEATURES), dtype=np.float32)\n    padded_atom_features[:num_nodes] = atom_features\n\n    edge_indices = []\n    for bond in mol.GetBonds():\n        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n        edge_indices.extend([[i, j], [j, i]])\n    \n    edge_index_array = np.array(edge_indices, dtype=np.int32) if edge_indices else np.zeros((0, 2), dtype=np.int32)\n\n    # SMILES features using the consistent tokenizer\n    token_ids = tokenize_smiles(smiles_string, max_len)\n    \n    return padded_atom_features, edge_index_array, np.array([num_nodes], dtype=np.int32), token_ids\n\n\n# --- TFRECORD SERIALIZATION ---\ndef _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef create_tf_example(atom_features, edge_index, num_nodes, token_ids, label, smiles_str):\n    \"\"\"Creates a tf.train.Example proto from a single molecule's data.\"\"\"\n    feature = {\n        'atom_features': _bytes_feature(tf.io.serialize_tensor(atom_features)),\n        'edge_index': _bytes_feature(tf.io.serialize_tensor(edge_index)),\n        'num_nodes': _bytes_feature(tf.io.serialize_tensor(num_nodes)),\n        'token_ids': _bytes_feature(tf.io.serialize_tensor(token_ids)),\n        'label': _bytes_feature(tf.io.serialize_tensor(label)),\n        'smiles': _bytes_feature(smiles_str.encode('utf-8')), # Save raw SMILES for future-proofing\n    }\n    return tf.train.Example(features=tf.train.Features(feature=feature))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T23:29:13.417916Z","iopub.execute_input":"2025-07-03T23:29:13.418282Z","iopub.status.idle":"2025-07-03T23:29:13.431788Z","shell.execute_reply.started":"2025-07-03T23:29:13.418259Z","shell.execute_reply":"2025-07-03T23:29:13.430662Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# --- MAIN PROCESSING LOOP ---\ndef process_and_save_datasets():\n    \"\"\"Main function to load, process, and save all specified datasets.\"\"\"\n    for name in DATASET_NAMES:\n        print(f\"\\n--- Processing dataset: {name} ---\")\n        \n        if name == 'Tox21':\n            tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='Raw', splitter='scaffold')\n        elif name == 'BBBP':\n            tasks, datasets, transformers = dc.molnet.load_bbbp(featurizer='Raw', splitter='scaffold')\n        elif name == 'ESOL':\n            tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='Raw', splitter='random')\n        else:\n            continue\n            \n        train_dataset, valid_dataset, test_dataset = datasets\n        \n        for split_name, dataset in [('train', train_dataset), ('valid', valid_dataset), ('test', test_dataset)]:\n            output_filename = os.path.join(OUTPUT_DIR, f'{name.lower()}_{split_name}.tfrecord')\n            \n            with tf.io.TFRecordWriter(output_filename) as writer:\n                processed_count = 0\n                for smiles, label in tqdm(zip(dataset.ids, dataset.y), total=len(dataset), desc=f\"  Writing {split_name}\"):\n                    \n                    featurized_data = smiles_to_graph_and_tokens(smiles, MAX_NODES, MAX_SMILES_LEN)\n                    if featurized_data is None:\n                        continue\n                    \n                    atom_f, edge_idx, num_n, token_ids = featurized_data\n                    label_np = np.array(label, dtype=np.float32)\n                    \n                    tf_example = create_tf_example(atom_f, edge_idx, num_n, token_ids, label_np, smiles)\n                    writer.write(tf_example.SerializeToString())\n                    processed_count += 1\n\n            print(f\"  ✅ Saved {processed_count} molecules to {output_filename}\")\n\n    print(f\"\\n--- All datasets processed successfully and saved in '{OUTPUT_DIR}'! ---\")\n\n# Run the entire preprocessing pipeline\nprocess_and_save_datasets()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-03T23:31:22.409772Z","iopub.execute_input":"2025-07-03T23:31:22.410202Z","iopub.status.idle":"2025-07-03T23:31:47.280075Z","shell.execute_reply.started":"2025-07-03T23:31:22.410172Z","shell.execute_reply":"2025-07-03T23:31:47.278480Z"}},"outputs":[{"name":"stdout","text":"\n--- Processing dataset: Tox21 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing train:   0%|          | 0/6258 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c559a6f7f8bb40cab4597e29f3898574"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 6258 molecules to moleculenet_tfrecords_final/tox21_train.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing valid:   0%|          | 0/782 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d3963688ac649dfbd1050ecbc75000a"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 782 molecules to moleculenet_tfrecords_final/tox21_valid.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing test:   0%|          | 0/783 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b702da3d535a4f88909e25b1fed5b6b5"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 783 molecules to moleculenet_tfrecords_final/tox21_test.tfrecord\n\n--- Processing dataset: BBBP ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing train:   0%|          | 0/1631 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c8f0c66ddd4230b64b6b6d15f41d0d"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 1631 molecules to moleculenet_tfrecords_final/bbbp_train.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing valid:   0%|          | 0/204 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe5eb1826524b668eb04ce5f1689d94"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 204 molecules to moleculenet_tfrecords_final/bbbp_valid.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing test:   0%|          | 0/204 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9fd5caa5dd0447ebc1a5edd0b0972fe"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 204 molecules to moleculenet_tfrecords_final/bbbp_test.tfrecord\n\n--- Processing dataset: ESOL ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing train:   0%|          | 0/902 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"339fafe99883479998acbdc1efea75d7"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 902 molecules to moleculenet_tfrecords_final/esol_train.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing valid:   0%|          | 0/113 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acad66c9215b43c6b1badb8c248edd93"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 113 molecules to moleculenet_tfrecords_final/esol_valid.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Writing test:   0%|          | 0/113 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a825821666f4c18aaaf99e53eaf8cd7"}},"metadata":{}},{"name":"stdout","text":"  ✅ Saved 113 molecules to moleculenet_tfrecords_final/esol_test.tfrecord\n\n--- All datasets processed successfully and saved in 'moleculenet_tfrecords_final'! ---\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}