{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12343939,"sourceType":"datasetVersion","datasetId":7781823}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"890b8a14-5a4b-450d-bae6-e4c05d231ddc","cell_type":"code","source":"# %%\n!pip install rdkit --quiet\n!pip install deepchem --quiet\n!pip install tqdm --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:20.898343Z","iopub.execute_input":"2025-07-01T18:56:20.898690Z","iopub.status.idle":"2025-07-01T18:56:30.734428Z","shell.execute_reply.started":"2025-07-01T18:56:20.898666Z","shell.execute_reply":"2025-07-01T18:56:30.733565Z"}},"outputs":[],"execution_count":1},{"id":"197d7125-c445-4931-a61f-f478adfd9ffa","cell_type":"code","source":"# %%\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom rdkit import Chem\nfrom tqdm import tqdm # For progress bars\n\n# Suppress non-critical RDKit warnings\nfrom rdkit import rdBase\nrdBase.DisableLog('rdApp.warning')\nrdBase.DisableLog('rdApp.error')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:30.736480Z","iopub.execute_input":"2025-07-01T18:56:30.736892Z","iopub.status.idle":"2025-07-01T18:56:35.059986Z","shell.execute_reply.started":"2025-07-01T18:56:30.736799Z","shell.execute_reply":"2025-07-01T18:56:35.059046Z"}},"outputs":[{"name":"stderr","text":"2025-07-01 18:56:31.056985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751396191.081378     260 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751396191.088792     260 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"id":"3e50710c-d61a-4799-9367-98dec399244a","cell_type":"code","source":"print(\"Checking for Metal GPU support on M1/Apple Silicon...\")\ntry:\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        print(f\"Found {len(gpus)} GPU(s) available.\")\n        strategy = tf.distribute.OneDeviceStrategy(device=\"/GPU:0\") \n        print(f\"Using Metal GPU strategy on: {gpus[0].name}\")\n    else:\n        print(\"No GPU (Metal) device found, defaulting to CPU.\")\n        strategy = tf.distribute.get_strategy() # Default to CPU strategy\nexcept Exception as e:\n    print(f\"Error during GPU detection/setup: {e}\")\n    print(\"Defaulting to CPU.\")\n    strategy = tf.distribute.get_strategy()\n\nprint(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:35.060755Z","iopub.execute_input":"2025-07-01T18:56:35.061190Z","iopub.status.idle":"2025-07-01T18:56:35.292500Z","shell.execute_reply.started":"2025-07-01T18:56:35.061170Z","shell.execute_reply":"2025-07-01T18:56:35.291778Z"}},"outputs":[{"name":"stdout","text":"Checking for Metal GPU support on M1/Apple Silicon...\nFound 1 GPU(s) available.\nUsing Metal GPU strategy on: /physical_device:GPU:0\nNumber of accelerators: 1\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1751396195.287462     260 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":3},{"id":"2207f7e8-4a62-473d-a3d6-402280904a03","cell_type":"code","source":"# --- IMPORTANT: Update PUBCHEM_TFRECORDS_DIR to your local path ---\n# This should point to the directory containing your pubchem_shard_XXX.tfrecord files.\nPUBCHEM_TFRECORDS_DIR = '/kaggle/input/pubchem-tfrecords-1m/pubchem_tfrecords_1M' # Directory created by preprocess_pubchem.py\n\n# --- Data Parameters (MUST match TFRecord creation) ---\nMAX_SMILES_LEN = 256 \nMAX_NODES = 419 # This MUST be the MAX_NODES used when creating the TFRecords\nNUM_ATOM_FEATURES = 5 # This MUST be the NUM_ATOM_FEATURES used when creating the TFRecords\n\n# --- Model Hyperparameters ---\nPROJECTION_DIM = 128 \nHIDDEN_DIM_GIN = 256 \nNUM_GIN_LAYERS = 3   \nEMBED_DIM_TRANSFORMER = 256 \nNUM_TRANSFORMER_HEADS = 8\nNUM_TRANSFORMER_LAYERS = 3\n\n# --- Training Parameters ---\nBATCH_SIZE_PER_REPLICA = 64 # Batch size per GPU. Adjust based on M1 memory.\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync # For 1 device, this is BATCH_SIZE_PER_REPLICA\nLEARNING_RATE = 1e-4\nTEMPERATURE = 0.07 # Temperature for InfoNCE Loss\nEPOCHS = 5 # Number of pre-training epochs.\n\n# --- Checkpointing and Resuming ---\nCHECKPOINT_DIR = 'pretraining_checkpoints' \nRESUME_TRAINING = False # Set to True to resume from the best saved model\nSTART_EPOCH = 0 # If resuming, set this to the epoch you want to start from (e.g., 3 to start epoch 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:35.294410Z","iopub.execute_input":"2025-07-01T18:56:35.294679Z","iopub.status.idle":"2025-07-01T18:56:35.300175Z","shell.execute_reply.started":"2025-07-01T18:56:35.294659Z","shell.execute_reply":"2025-07-01T18:56:35.299213Z"}},"outputs":[],"execution_count":4},{"id":"fd839c4b-0e7e-46b6-ae5c-9b23a6a950cb","cell_type":"code","source":"# --- SMILES Tokenization ---\ndef build_smiles_vocab(smiles_list, max_vocab_size=None):\n    all_chars = set()\n    for smiles in smiles_list:\n        for char in smiles:\n            all_chars.add(char)\n    vocab = sorted(list(all_chars))\n    vocab = ['<pad>', '<unk>', '<cls>', '<eos>'] + vocab\n    if max_vocab_size:\n        vocab = vocab[:max_vocab_size]\n    char_to_idx = {char: i for i, char in enumerate(vocab)}\n    idx_to_char = {i: char for i, char in enumerate(vocab)}\n    print(f\"Built vocabulary of size: {len(vocab)}\")\n    return vocab, char_to_idx, idx_to_char\n\ndef tokenize_smiles(smiles, char_to_idx, max_len):\n    tokens = list(smiles)\n    indexed_tokens = [char_to_idx.get(char, char_to_idx['<unk>']) for char in tokens]\n    if len(indexed_tokens) < max_len:\n        padded_tokens = indexed_tokens + [char_to_idx['<pad>']] * (max_len - len(indexed_tokens))\n    else:\n        padded_tokens = indexed_tokens[:max_len]\n    return np.array(padded_tokens, dtype=np.int32)\n\ndef create_smiles_mask(token_ids, pad_token_id):\n    return tf.cast(token_ids == pad_token_id, tf.bool)\n\n\n# --- SMILES to TensorFlow Graph Conversion ---\ndef atom_to_feature_vector(atom):\n    features = []\n    features.append(atom.GetAtomicNum())\n    features.append(atom.GetDegree())\n    features.append(int(atom.GetHybridization()))\n    features.append(int(atom.GetIsAromatic()))\n    features.append(atom.GetFormalCharge())\n    return np.array(features, dtype=np.float32)\n\n# NUM_ATOM_FEATURES defined after atom_to_feature_vector is available\nNUM_ATOM_FEATURES = len(atom_to_feature_vector(Chem.Atom(6))) \n\ndef smiles_to_tf_graph(smiles_string):\n    mol = Chem.MolFromSmiles(smiles_string)\n    if mol is None:\n        return (np.zeros((0, NUM_ATOM_FEATURES), dtype=np.float32),\n                np.zeros((0, 2), dtype=np.int32),\n                0,\n                0)\n\n    node_features = [atom_to_feature_vector(atom) for atom in mol.GetAtoms()]\n    if not node_features:\n        return (np.zeros((0, NUM_ATOM_FEATURES), dtype=np.float32),\n                np.zeros((0, 2), dtype=np.int32),\n                0,\n                0)\n    node_features = np.array(node_features, dtype=np.float32)\n    num_nodes = len(node_features)\n\n    edge_indices = []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_indices.append([i, j])\n        edge_indices.append([j, i])\n\n    num_edges = len(edge_indices)\n    if num_edges == 0:\n        if num_nodes > 0:\n            edge_indices_final = np.empty((0, 2), dtype=np.int32)\n            num_edges_final = 0\n        else:\n            return (np.zeros((0, NUM_ATOM_FEATURES), dtype=np.float32),\n                    np.zeros((0, 2), dtype=np.int32),\n                    0,\n                    0)\n    else:\n        edge_indices_final = np.array(edge_indices, dtype=np.int32)\n        num_edges_final = len(edge_indices_final)\n\n    return node_features, edge_indices_final, num_nodes, num_edges_final\n\n\n# --- TFRecord Parsing Function ---\ndef parse_tfrecord_example_pretraining(example_proto):\n    feature_description = {\n        'node_feat_padded': tf.io.FixedLenFeature([], tf.string),\n        'edge_idx': tf.io.FixedLenFeature([], tf.string),\n        'num_nodes': tf.io.FixedLenFeature([], tf.int64),\n        'num_edges': tf.io.FixedLenFeature([], tf.int64),\n        'token_ids': tf.io.FixedLenFeature([], tf.string),\n        'smiles_mask': tf.io.FixedLenFeature([], tf.string),\n    }\n\n    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n\n    # Decode raw bytes back to tensors and reshape\n    node_feat_padded = tf.io.decode_raw(parsed_features['node_feat_padded'], tf.float32)\n    node_feat_padded = tf.reshape(node_feat_padded, [MAX_NODES, NUM_ATOM_FEATURES])\n\n    edge_idx = tf.io.decode_raw(parsed_features['edge_idx'], tf.int32)\n    edge_idx = tf.reshape(edge_idx, [-1, 2]) # -1 infers the first dimension (number of edges)\n\n    num_nodes = tf.cast(parsed_features['num_nodes'], tf.int32)\n    num_edges = tf.cast(parsed_features['num_edges'], tf.int32)\n\n    token_ids = tf.io.decode_raw(parsed_features['token_ids'], tf.int32)\n    token_ids = tf.reshape(token_ids, [MAX_SMILES_LEN])\n\n    smiles_mask = tf.io.decode_raw(parsed_features['smiles_mask'], tf.bool)\n    smiles_mask = tf.reshape(smiles_mask, [MAX_SMILES_LEN])\n\n    # Return the 6 components as a tuple matching the model's input structure\n    return (node_feat_padded, edge_idx, num_nodes, num_edges, token_ids, smiles_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:35.300964Z","iopub.execute_input":"2025-07-01T18:56:35.301234Z","iopub.status.idle":"2025-07-01T18:56:35.324702Z","shell.execute_reply.started":"2025-07-01T18:56:35.301216Z","shell.execute_reply":"2025-07-01T18:56:35.324015Z"}},"outputs":[],"execution_count":5},{"id":"85e193e3-adbe-47dc-a50e-27164e89f82f","cell_type":"code","source":"print(\"Building vocabulary for pre-training data...\")\ndummy_smiles_for_vocab_build = [\"C\", \"N\", \"O\", \"F\", \"P\", \"S\", \"Cl\", \"Br\", \"I\", \"c\", \"n\", \"=\", \"#\", \"(\", \")\", \"[\", \"]\", \"@\", \"+\", \"-\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"H\", \"B\", \"b\", \"K\", \"k\", \"L\", \"l\", \"M\", \"m\", \"R\", \"r\", \"X\", \"x\", \"Y\", \"y\", \"Z\", \"z\"] \n_, char_to_idx, _ = build_smiles_vocab(dummy_smiles_for_vocab_build)\nVOCAB_SIZE = len(char_to_idx) \nprint(f\"Vocabulary built with {VOCAB_SIZE} tokens for pre-training.\")\n\n\n# %%\n# Define padded_shapes for the output of featurize_smiles_and_graph\npadded_shapes = (\n    tf.TensorShape([MAX_NODES, NUM_ATOM_FEATURES]), # node_features\n    tf.TensorShape([None, 2]),                     # edge_indices (variable length per graph in batch)\n    tf.TensorShape([]),                           # num_nodes\n    tf.TensorShape([]),                           # num_edges\n    tf.TensorShape([MAX_SMILES_LEN]),              # token_ids\n    tf.TensorShape([MAX_SMILES_LEN])               # smiles_mask\n)\npadding_values = (\n    tf.constant(0.0, dtype=tf.float32),\n    tf.constant(0, dtype=tf.int32),\n    tf.constant(0, dtype=tf.int32),\n    tf.constant(0, dtype=tf.int32),\n    tf.constant(char_to_idx['<pad>'], dtype=tf.int32),\n    tf.constant(False, dtype=tf.bool) \n)\n\n# Function to load pre-processed TFRecord dataset\ndef load_tfrecord_pretraining_dataset(tfrecord_dir, batch_size, shuffle_buffer_size=100000):\n    # List all TFRecord files\n    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, '*.tfrecord'))\n    print(f\"Found {len(tfrecord_files)} TFRecord shards in {tfrecord_dir}\")\n    if not tfrecord_files:\n        raise FileNotFoundError(f\"No TFRecord files found in {tfrecord_dir}. Please run preprocess_pubchem.py first.\")\n    \n    # Create dataset from TFRecord files\n    dataset = tf.data.TFRecordDataset(tfrecord_files)\n    \n    # Pass the explicit output_signature to the map function\n    # This ensures TF knows the exact structure and types returned by the parsing function.\n    parse_output_signature = (\n        tf.TensorSpec(shape=[MAX_NODES, NUM_ATOM_FEATURES], dtype=tf.float32), # node_feat_padded\n        tf.TensorSpec(shape=[None, 2], dtype=tf.int32),                     # edge_idx\n        tf.TensorSpec(shape=[], dtype=tf.int32),                             # num_nodes\n        tf.TensorSpec(shape=[], dtype=tf.int32),                             # num_edges\n        tf.TensorSpec(shape=[MAX_SMILES_LEN], dtype=tf.int32),                # token_ids\n        tf.TensorSpec(shape=[MAX_SMILES_LEN], dtype=tf.bool)                 # smiles_mask\n    )\n    dataset = dataset.map(parse_tfrecord_example_pretraining, \n                          num_parallel_calls=tf.data.AUTOTUNE) \n    \n    dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n    \n    dataset = dataset.padded_batch(batch_size, \n                                   padded_shapes=padded_shapes, # Use the globally defined padded_shapes\n                                   padding_values=padding_values, # Use the globally defined padding_values\n                                   drop_remainder=True)\n    dataset = dataset.repeat() # Repeat indefinitely for pre-training\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset\n\n# Load the pre-processed TFRecord dataset\ndataset = load_tfrecord_pretraining_dataset(PUBCHEM_TFRECORDS_DIR, GLOBAL_BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:35.326122Z","iopub.execute_input":"2025-07-01T18:56:35.326713Z","iopub.status.idle":"2025-07-01T18:56:35.561877Z","shell.execute_reply.started":"2025-07-01T18:56:35.326692Z","shell.execute_reply":"2025-07-01T18:56:35.561258Z"}},"outputs":[{"name":"stdout","text":"Building vocabulary for pre-training data...\nBuilt vocabulary of size: 49\nVocabulary built with 49 tokens for pre-training.\nFound 100 TFRecord shards in /kaggle/input/pubchem-tfrecords-1m/pubchem_tfrecords_1M\n","output_type":"stream"}],"execution_count":6},{"id":"fecbc7bc-0cef-4637-b418-ec38b73c5bfe","cell_type":"code","source":"# GIN Layer\nclass GINLayer(layers.Layer):\n    def __init__(self, output_dim, activation=None, **kwargs):\n        super(GINLayer, self).__init__(**kwargs)\n        self.output_dim = output_dim\n        self.mlp = keras.Sequential([\n            layers.Dense(output_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n        self.epsilon = self.add_weight(name='epsilon', shape=(),\n                                       initializer=keras.initializers.Constant(0.0),\n                                       trainable=True)\n        self.activation = keras.activations.get(activation)\n\n    def call(self, inputs):\n        node_features, edge_indices_batch, num_nodes_batch = inputs # num_nodes_batch is unused here, but passed\n        \n        edge_values = tf.ones(tf.shape(edge_indices_batch)[0], dtype=tf.float32)\n        \n        total_nodes_in_batch = tf.shape(node_features)[0]\n        adj_shape = tf.cast([total_nodes_in_batch, total_nodes_in_batch], dtype=tf.int64)\n\n        adj_sparse = tf.sparse.SparseTensor(indices=tf.cast(edge_indices_batch, tf.int64),\n                                            values=edge_values,\n                                            dense_shape=adj_shape)\n        \n        neighbor_sum = tf.sparse.sparse_dense_matmul(adj_sparse, node_features)\n\n        combined_features = (1 + self.epsilon) * node_features + neighbor_sum\n        output = self.mlp(combined_features)\n\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0][0], self.output_dim\n\n# GIN Encoder\nclass GINEncoder(keras.Model):\n    def __init__(self, num_layers, hidden_dim, num_node_features, **kwargs): \n        super(GINEncoder, self).__init__(**kwargs)\n        self.hidden_dim = hidden_dim \n        self.initial_mlp = keras.Sequential([\n            layers.Dense(hidden_dim, activation='relu'),\n            layers.Dense(hidden_dim) \n        ])\n        self.gin_layers = []\n        self.bns = []\n        for i in range(num_layers): \n            self.gin_layers.append(GINLayer(hidden_dim, activation='relu' if i < num_layers - 1 else None))\n            self.bns.append(layers.BatchNormalization())\n    \n    def call(self, inputs):\n        node_features, edge_indices, num_nodes = inputs\n        x = self.initial_mlp(node_features)\n        for i in range(len(self.gin_layers)): \n            x = self.gin_layers[i]((x, edge_indices, num_nodes))\n            x = self.bns[i](x)\n        \n        batch_size = tf.shape(node_features)[0] // MAX_NODES\n        x_reshaped = tf.reshape(x, (batch_size, MAX_NODES, self.hidden_dim)) \n        sequence_mask = tf.sequence_mask(num_nodes, maxlen=MAX_NODES, dtype=tf.float32) \n        sequence_mask = tf.expand_dims(sequence_mask, axis=-1) \n        masked_x = x_reshaped * sequence_mask\n        graph_embedding = tf.reduce_sum(masked_x, axis=1)\n        return graph_embedding\n\n# Transformer Encoder\nclass TransformerEncoder(keras.Model):\n    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, max_seq_len, dropout_rate=0.1, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.token_embedding = layers.Embedding(vocab_size, embed_dim)\n        self.positional_embedding = self.add_weight(\n            name=\"pos_embed\",\n            shape=(1, max_seq_len, embed_dim),\n            initializer=\"random_normal\",\n            trainable=True\n        )\n        self.encoder_layers = []\n        for _ in range(num_layers):\n            self.encoder_layers.append([\n                layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout_rate),\n                layers.LayerNormalization(epsilon=1e-6),\n                layers.Dense(embed_dim * 4, activation=\"relu\"),\n                layers.Dense(embed_dim),\n                layers.LayerNormalization(epsilon=1e-6),\n            ])\n        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, inputs, training=False, mask=None):\n        token_ids, padding_mask_bool = inputs \n        x = self.token_embedding(token_ids)\n        x = x + self.positional_embedding[:, :tf.shape(x)[1], :]\n        attention_mask_additive = tf.cast(padding_mask_bool, dtype=tf.float32) * -1e9\n        attention_mask_additive = tf.expand_dims(attention_mask_additive, axis=1) \n        \n        for i, (attention, norm1, ff_dense1, ff_dense2, norm2) in enumerate(self.encoder_layers):\n            attn_output = attention(x, x, attention_mask=attention_mask_additive, training=training)\n            x = norm1(x + attn_output)\n            ff_output = ff_dense2(ff_dense1(x))\n            x = norm2(x + ff_output)\n        \n        expanded_padding_mask = tf.cast(tf.expand_dims(padding_mask_bool, axis=-1), dtype=x.dtype)\n        non_padded_mask = 1.0 - expanded_padding_mask\n        x_masked = x * non_padded_mask\n        sum_embeddings = tf.reduce_sum(x_masked, axis=1)\n        non_padded_len = tf.reduce_sum(non_padded_mask, axis=1)\n        smiles_embedding = sum_embeddings / (non_padded_len + 1e-9)\n        \n        return self.final_norm(smiles_embedding)\n\n# Projection Head\nclass ProjectionHead(keras.Model):\n    def __init__(self, input_dim, output_dim, hidden_dim=256, **kwargs):\n        super(ProjectionHead, self).__init__(**kwargs)\n        self.net = keras.Sequential([\n            layers.Dense(hidden_dim, activation='relu'),\n            layers.Dense(output_dim)\n        ])\n\n    def call(self, x):\n        return self.net(x)\n\n# GRASP Model (Dual-Brain Architecture)\nclass GRASPModel(keras.Model):\n    def __init__(self, gin_config, transformer_config, projection_dim, **kwargs):\n        super(GRASPModel, self).__init__(**kwargs)\n        self.gin_encoder = GINEncoder(**gin_config)\n        self.transformer_encoder = TransformerEncoder(**transformer_config)\n        \n        self.graph_projection_head = ProjectionHead(gin_config['hidden_dim'], projection_dim)\n        self.smiles_projection_head = ProjectionHead(transformer_config['embed_dim'], projection_dim)\n    \n    def call(self, inputs, training=False):\n        # Inputs are unpacked from the dataset tuple\n        node_features_padded, edge_indices_padded, num_nodes, num_edges, token_ids, smiles_mask = inputs\n        \n        node_features_flat = tf.reshape(node_features_padded, (-1, tf.shape(node_features_padded)[2]))\n        \n        batch_size = tf.shape(node_features_padded)[0] \n        \n        # --- Handling Edge Indices for GINLayer ---\n        edge_mask = tf.sequence_mask(num_edges, maxlen=tf.shape(edge_indices_padded)[1], dtype=tf.bool)\n        valid_edge_indices = tf.cast(tf.boolean_mask(edge_indices_padded, edge_mask), dtype=tf.int32) \n        batch_ids_for_edges = tf.cast(tf.where(edge_mask)[:, 0], dtype=tf.int32)\n        node_offsets_for_edges = tf.range(batch_size) * MAX_NODES\n        offsets = tf.gather(node_offsets_for_edges, batch_ids_for_edges)\n        offsets = tf.expand_dims(offsets, axis=-1)\n        global_edge_indices_filtered = valid_edge_indices + offsets\n        \n        # Get embeddings from pre-trained encoders\n        graph_embeddings_raw = self.gin_encoder((node_features_flat, global_edge_indices_filtered, num_nodes), training=training)\n        smiles_embeddings_raw = self.transformer_encoder((token_ids, smiles_mask), training=training)\n        \n        # Apply L2 normalization to projected embeddings for InfoNCE loss\n        graph_embeddings_projected = self.graph_projection_head(graph_embeddings_raw)\n        smiles_embeddings_projected = self.smiles_projection_head(smiles_embeddings_raw)\n        \n        graph_embeddings_projected = tf.linalg.normalize(graph_embeddings_projected, axis=1)[0]\n        smiles_embeddings_projected = tf.linalg.normalize(smiles_embeddings_projected, axis=1)[0]\n        \n        return graph_embeddings_projected, smiles_embeddings_projected","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:35.562683Z","iopub.execute_input":"2025-07-01T18:56:35.562916Z","iopub.status.idle":"2025-07-01T18:56:35.585660Z","shell.execute_reply.started":"2025-07-01T18:56:35.562898Z","shell.execute_reply":"2025-07-01T18:56:35.584870Z"}},"outputs":[],"execution_count":7},{"id":"f2c793f5-5a03-4ee9-bc1c-2285dacc2b45","cell_type":"code","source":"class InfoNCELoss(keras.losses.Loss):\n    def __init__(self, temperature=0.07, name='info_nce_loss', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.temperature = temperature\n\n    @tf.function\n    def call(self, graph_embeddings, smiles_embeddings):\n        logits = tf.matmul(graph_embeddings, smiles_embeddings, transpose_b=True) / self.temperature\n        batch_size = tf.shape(logits)[0]\n        labels = tf.eye(batch_size)\n        loss_g_s = tf.keras.losses.categorical_crossentropy(labels, logits, from_logits=True)\n        loss_s_g = tf.keras.losses.categorical_crossentropy(labels, tf.transpose(logits), from_logits=True)\n        total_loss = (loss_g_s + loss_s_g) / 2\n        return tf.reduce_mean(total_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:35.586395Z","iopub.execute_input":"2025-07-01T18:56:35.586695Z","iopub.status.idle":"2025-07-01T18:56:35.605534Z","shell.execute_reply.started":"2025-07-01T18:56:35.586666Z","shell.execute_reply":"2025-07-01T18:56:35.604782Z"}},"outputs":[],"execution_count":8},{"id":"4fa73151-a251-42ee-9ca4-33ebc5346288","cell_type":"code","source":"with strategy.scope(): # Model and optimizer instantiation within strategy scope\n    gin_config = {\n        'num_layers': NUM_GIN_LAYERS,\n        'hidden_dim': HIDDEN_DIM_GIN,\n        'num_node_features': NUM_ATOM_FEATURES\n    }\n\n    transformer_config = {\n        'vocab_size': VOCAB_SIZE,\n        'embed_dim': EMBED_DIM_TRANSFORMER,\n        'num_heads': NUM_TRANSFORMER_HEADS,\n        'num_layers': NUM_TRANSFORMER_LAYERS,\n        'max_seq_len': MAX_SMILES_LEN\n    }\n\n    # Create checkpoint directory if it doesn't exist\n    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n    model = GRASPModel(gin_config, transformer_config, PROJECTION_DIM)\n    info_nce_loss = InfoNCELoss(temperature=TEMPERATURE)\n    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\n    # Load checkpoint if resuming training\n    if RESUME_TRAINING:\n        try:\n            print(f\"Attempting to resume training from {CHECKPOINT_DIR}/gin_encoder_best and {CHECKPOINT_DIR}/transformer_encoder_best\")\n            loaded_gin_encoder = tf.saved_model.load(os.path.join(CHECKPOINT_DIR, 'gin_encoder_best'))\n            loaded_transformer_encoder = tf.saved_model.load(os.path.join(CHECKPOINT_DIR, 'transformer_encoder_best'))\n            \n            # Assign loaded encoders to the model's attributes\n            model.gin_encoder = loaded_gin_encoder\n            model.transformer_encoder = loaded_transformer_encoder\n            print(\"Model loaded successfully for resuming.\")\n            # Note: Optimizer state is NOT restored here. Learning rate schedule will restart.\n        except Exception as e:\n            print(f\"Could not load checkpoint for resuming: {e}. Starting training from scratch.\")\n            RESUME_TRAINING = False # Reset flag if loading fails\n\n    # The train_step function performs a single gradient update.\n    @tf.function(reduce_retracing=True)\n    def train_step(inputs):\n        with tf.GradientTape() as tape:\n            graph_embeddings, smiles_embeddings = model(inputs, training=True)\n            loss = info_nce_loss(graph_embeddings, smiles_embeddings)\n        \n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n        return loss\n\n# Determine the number of steps per epoch for tqdm\n# This should be calculated based on the total number of samples in the TFRecords\n# For 1 million samples, if each shard has ~100MB, and each sample is ~10KB,\n# 1M samples * 10KB/sample = 10GB total.\n# If GLOBAL_BATCH_SIZE is 64, then 1,000,000 / 64 = 15625 steps per epoch.\n# We need to get the exact count from the TFRecords.\n# For now, estimate based on the target 1M samples.\ntotal_samples_in_tfrecords = 1_000_000 # This should be the actual count from your preprocessing\nsteps_per_epoch_tqdm = total_samples_in_tfrecords // GLOBAL_BATCH_SIZE\nsteps_per_epoch_tqdm = max(1, steps_per_epoch_tqdm)\n\nprint(f\"\\nStarting pre-training for {EPOCHS} epochs...\")\nprint(f\"Dataset has {steps_per_epoch_tqdm} batches per epoch.\")\n\nbest_val_loss = float('inf') # Initialize best loss for saving best model\n\nfor epoch in range(START_EPOCH, EPOCHS): # Use START_EPOCH for resuming\n    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n    total_loss = 0.0\n    \n    epoch_iterator = tqdm(dataset, desc=f\"Epoch {epoch + 1} Training\", total=steps_per_epoch_tqdm, leave=True)\n    \n    num_batches = 0 \n\n    for i, batch_inputs in enumerate(epoch_iterator):\n        per_replica_losses = strategy.run(train_step, args=(batch_inputs,))\n        # Reduce sum across replicas (will be just the loss itself for OneDeviceStrategy)\n        batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n        \n        total_loss += batch_loss\n        num_batches += 1\n        \n        epoch_iterator.set_postfix(loss=f\"{batch_loss.numpy():.4f}\")\n    \n    if num_batches > 0: \n        avg_loss = total_loss / num_batches\n        print(f\"\\nEpoch {epoch + 1} finished. Average Loss: {avg_loss:.4f}\")\n\n        # --- Checkpointing Logic ---\n        current_gin_path = os.path.join(CHECKPOINT_DIR, f'gin_encoder_epoch_{epoch+1}')\n        current_transformer_path = os.path.join(CHECKPOINT_DIR, f'transformer_encoder_epoch_{epoch+1}')\n        \n        tf.saved_model.save(model.gin_encoder, current_gin_path)\n        tf.saved_model.save(model.transformer_encoder, current_transformer_path)\n        print(f\"Epoch {epoch+1} encoders saved to {CHECKPOINT_DIR}\")\n\n        if avg_loss < best_val_loss:\n            best_val_loss = avg_loss\n            best_gin_path = os.path.join(CHECKPOINT_DIR, 'gin_encoder_best')\n            best_transformer_path = os.path.join(CHECKPOINT_DIR, 'transformer_encoder_best')\n            \n            tf.saved_model.save(model.gin_encoder, best_gin_path)\n            tf.saved_model.save(model.transformer_encoder, best_transformer_path)\n            print(f\"New best model saved at epoch {epoch+1} with loss {best_val_loss:.4f}\")\n\n    else:\n        print(f\"\\nEpoch {epoch + 1} finished. No batches processed (check dataset size/filtering).\\n\") # Added newline for clarity\n\nprint(\"\\nPre-training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:56:35.606623Z","iopub.execute_input":"2025-07-01T18:56:35.606881Z"}},"outputs":[{"name":"stdout","text":"\nStarting pre-training for 5 epochs...\nDataset has 15625 batches per epoch.\n\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 Training:  26%|██▋       | 4138/15625 [09:52<25:57,  7.38it/s, loss=0.2015] ","output_type":"stream"}],"execution_count":null},{"id":"436d64c0-1a13-43b1-9e92-5a20d34ca0e4","cell_type":"code","source":"# Final save of the encoders (redundant if best model is saved on last epoch, but ensures last state is saved)\ntf.saved_model.save(model.gin_encoder, 'gin_encoder_final')\ntf.saved_model.save(model.transformer_encoder, 'transformer_encoder_final')\nprint(\"Final Encoders saved.\")\n\n# Optionally, save the entire pre-trained GRASP model as well\nmodel.export('grasp_pretrained_model_tf_savedmodel')\nprint(\"Full Model saved to 'grasp_pretrained_model_tf_savedmodel' directory.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"53f15987-a6ed-4c5b-87ff-25efca83f023","cell_type":"code","source":"print(\"\\n--- Starting Post-Pretraining Qualitative Evaluation ---\")\n\ntry:\n    if 'model' not in locals() or not hasattr(model, 'gin_encoder') or not hasattr(model, 'transformer_encoder'):\n        print(\"Loading encoders from disk...\")\n        loaded_gin_encoder = tf.saved_model.load('gin_encoder_final') # Load final saved encoders\n        loaded_transformer_encoder = tf.saved_model.load('transformer_encoder_final')\n    else:\n        print(\"Using encoders directly from trained model in memory.\")\n        loaded_gin_encoder = model.gin_encoder\n        loaded_transformer_encoder = model.transformer_encoder\n\nexcept Exception as e:\n    print(f\"Error loading encoders: {e}. Make sure they were saved correctly and paths are valid.\")\n    print(\"Skipping qualitative evaluation.\")\n    import sys\n    sys.exit() \n\n# Helper function to get embeddings for a single SMILES string\ndef get_single_molecule_embeddings(smiles_string, gin_encoder, transformer_encoder):\n    token_ids = tokenize_smiles(smiles_string, char_to_idx, MAX_SMILES_LEN)\n    smiles_mask = create_smiles_mask(token_ids, char_to_idx['<pad>'])\n\n    node_features, edge_indices, num_nodes, num_edges = smiles_to_tf_graph(smiles_string)\n\n    if num_nodes == 0: \n        print(f\"Warning: Could not featurize SMILES '{smiles_string}'. Skipping.\")\n        return None, None\n    \n    padded_node_features = tf.pad(node_features, [[0, MAX_NODES - num_nodes], [0, 0]])\n    \n    node_features_for_gin = tf.reshape(padded_node_features, (1 * MAX_NODES, NUM_ATOM_FEATURES)) \n    edge_indices_for_gin = tf.cast(edge_indices, dtype=tf.int32) \n    num_nodes_for_gin = tf.constant([num_nodes], dtype=tf.int32)\n    \n    token_ids_for_transformer = tf.expand_dims(token_ids, axis=0) \n    smiles_mask_for_transformer = tf.expand_dims(smiles_mask, axis=0) \n    \n    graph_embedding = gin_encoder((node_features_for_gin, edge_indices_for_gin, num_nodes_for_gin), training=False)\n    smiles_embedding = transformer_encoder((token_ids_for_transformer, smiles_mask_for_transformer), training=False)\n    \n    graph_embedding_normalized = tf.linalg.normalize(graph_embedding, axis=1)[0]\n    smiles_embedding_normalized = tf.linalg.normalize(smiles_embedding, axis=1)[0]\n\n    return graph_embedding_normalized, smiles_embedding_normalized\n\n\n# --- Test Cases ---\ntest_smiles = [\n    \"CCO\",      # Ethanol (small, simple alcohol)\n    \"c1ccccc1\", # Benzene (aromatic ring)\n    \"O=C(Cl)c1ccccc1\", # Benzoyl chloride (more complex, functional group)\n    \"CC(=O)Oc1ccccc1C(=O)O\", # Aspirin (larger, common drug)\n    \"C\" # Methane (single atom, check edge case)\n]\n\nall_graph_embeddings = []\nall_smiles_embeddings = []\nvalid_smiles_for_eval = []\n\nfor smiles in test_smiles:\n    g_embed, s_embed = get_single_molecule_embeddings(smiles, loaded_gin_encoder, loaded_transformer_encoder)\n    if g_embed is not None and s_embed is not None:\n        all_graph_embeddings.append(g_embed)\n        all_smiles_embeddings.append(s_embed)\n        valid_smiles_for_eval.append(smiles)\n    \nif not valid_smiles_for_eval:\n    print(\"No valid SMILES were processed for qualitative evaluation.\")\nelse:\n    all_graph_embeddings_tensor = tf.concat(all_graph_embeddings, axis=0) \n    all_smiles_embeddings_tensor = tf.concat(all_smiles_embeddings, axis=0) \n\n    print(\"\\n--- Cosine Similarity Matrix (Graph vs. SMILES) ---\")\n    similarity_matrix = tf.matmul(all_graph_embeddings_tensor, all_smiles_embeddings_tensor, transpose_b=True).numpy()\n\n    print(\"Rows: Graph Embeddings of [SMILES]\\nCols: SMILES Embeddings of [SMILES]\")\n    print(\" \" * 10 + \"\".join([f\"{s[:8]:<10}\" for s in valid_smiles_for_eval])) \n    print(\"-\" * (10 + len(valid_smiles_for_eval) * 10))\n\n    for i, smiles_i in enumerate(valid_smiles_for_eval):\n        row_str = f\"{smiles_i[:8]:<10}\" \n        for j in range(len(valid_smiles_for_eval)):\\\n            row_str += f\"{similarity_matrix[i, j]:<10.4f}\"\n        print(row_str)\n    print(\"-\" * (10 + len(valid_smiles_for_eval) * 10))\n\n    print(\"\\n--- Key Observations ---\")\n    print(\"Expected: High values on the diagonal (positive pairs), low values off-diagonal (negative pairs).\\n\")\n    print(\"This indicates that the pre-trained model successfully learns to align graph and SMILES representations of the same molecule.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3a63bd43-9443-4ca6-9192-b86d8900cbab","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}